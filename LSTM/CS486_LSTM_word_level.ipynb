{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS486 LSTM word-level.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPREGT3rZ7NJpGxpmuF5O6G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Da-Pen/CS486-twitter-bot/blob/main/LSTM/CS486_LSTM_word_level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzpWcqefq1_m",
        "outputId": "ac254262-879e-4213-83d0-613ae5e1d899",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# CONSTANTS\n",
        "NEWS_ORGS_DATA_FILE_NAME = '/content/data/newsorgs_data'\n",
        "TRUMP_DATA_FILE_NAME = '/content/data/donald_trump_data'\n",
        "ONLY_LOWERCASE = True\n",
        "SKIP_URLS = True\n",
        "SKIP_ELLIPSES = True\n",
        "SKIP_RETWEETS = True\n",
        "SKIP_REPLIES = True     # it seems like Trump often has tweets where he simply replies to another Twitter user or quotes them. They usually start with '@' or '\"@'. If this is set to true, then ignore those tweets.\n",
        "MIN_TWEET_LENGTH = 50 # characters\n",
        "\n",
        "# returns a string minus all the urls in it\n",
        "def ignore_urls(s):\n",
        "    return ' '.join([x for x in s.split() if 'http' not in x])\n",
        "\n",
        "\n",
        "# returns True for words like 'Hello' and 'hello' but not 'HELLO' or 'HelLo'\n",
        "def is_normal_capitalization(word):\n",
        "    return word[1:].islower()\n",
        "\n",
        "# replaces 'Abcdef' with 'abcdef' but leaves 'ABCDEF' and 'AbCdeF' intact\n",
        "def replace_first_caps(sentence):\n",
        "    return ' '.join([word.lower() if is_normal_capitalization(word) else word for word in sentence.split(' ')])\n",
        "\n",
        "# gets a list of strings representing the tweets in the given file.\n",
        "# can limit the number of tweets to get using upto.\n",
        "# replaces 'NEWLINE's with actual \\n characters.\n",
        "def get_tweets_list(filename, upto=None):\n",
        "    f = open(filename, 'r')\n",
        "    lines = f.read().split('\\n')[:upto]\n",
        "    f.close()\n",
        "    # replace NEWLINE's and ignore all lines that do not have spaces (because they are probably just a link)\n",
        "    lines = [line.replace('NEWLINE', '\\n') for line in lines if line.strip().find(' ') != -1]\n",
        "    if ONLY_LOWERCASE:\n",
        "        lines = [replace_first_caps(line) for line in lines]\n",
        "    if SKIP_ELLIPSES:  # skip tweets with the '…' character, which indicates that it has been truncated\n",
        "        lines = [line for line in lines if line.find('…') == -1]\n",
        "    if SKIP_URLS:\n",
        "        lines = [ignore_urls(line) for line in lines]\n",
        "    if SKIP_RETWEETS:\n",
        "        lines = [line for line in lines if line[:2] != 'RT']\n",
        "    if SKIP_REPLIES:\n",
        "        lines = [line for line in lines if len(line) > 0 and line[0] != '@' and line[:2] != '\"@']\n",
        "    # # check what percentage of characters are valid: if less than MIN_VALID_CHAR_PERCENT are valid, then ignore this tweet. Otherwise, delete invalid characters.\n",
        "    # lines = [filter_invalid_chars(line) for line in lines if filter_invalid_chars(line) is not None]\n",
        "    return np.array(lines)\n",
        "\n",
        "# given a list of tweets, gets a map of words to occurrences\n",
        "def get_words(tweets):\n",
        "    all_words = defaultdict(lambda: 0)\n",
        "    for tweet in tweets:\n",
        "        words = tweet.split(' ')\n",
        "        for word in words:\n",
        "            all_words[word] += 1\n",
        "    return all_words\n",
        "\n",
        "def get_words_list(words_map):\n",
        "    min_occurrence = 5\n",
        "    words_list = []\n",
        "    for word in words_map.keys():\n",
        "        if words_map[word] > min_occurrence:\n",
        "            words_list.append(word)\n",
        "    return words_list\n",
        "\n",
        "\n",
        "def filter_words(tweet, words_set):\n",
        "    return ' '.join([word for word in tweet.split(' ') if word in words_set])\n",
        "\n",
        "# tweets = get_tweets_list(TRUMP_DATA_FILE_NAME)\n",
        "tweets = get_tweets_list(NEWS_ORGS_DATA_FILE_NAME)\n",
        "\n",
        "words_list = get_words_list(get_words(tweets))\n",
        "word_to_index = dict((c, i) for i, c in enumerate(words_list))\n",
        "index_to_word = dict((i, c) for i, c in enumerate(words_list))\n",
        "print('there are', len(words_list), 'words')\n",
        "print(words_list)\n",
        "words_set = set(words_list)\n",
        "# ignore all invalid words in tweets\n",
        "print(\"BEFORE filtering, there were\", len(tweets), \"tweets\")\n",
        "new_tweets = []\n",
        "for tweet in tweets:\n",
        "    filtered_tweet = filter_words(tweet, words_set)\n",
        "    if len(filtered_tweet) > 0.8*len(tweet):\n",
        "        new_tweets.append(filtered_tweet)\n",
        "tweets = new_tweets\n",
        "\n",
        "# filter short tweets\n",
        "tweets = [tweet for tweet in tweets if len(tweet) > MIN_TWEET_LENGTH]\n",
        "\n",
        "print(\"AFTER filtering, there are\", len(tweets), \"tweets\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    pass    # do nothing (may comment out if we want to test something)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 7806 words\n",
            "['organizers', 'announced', 'that', 'canadian', 'singer', 'the', 'will', 'perform', 'at', '2021', 'super', 'show.', 'new', 'projections', 'by', \"ontario's\", 'science', 'advisory', 'table', 'show', 'pandemic', 'is', 'worsening', 'across', 'province', 'quebec', 'premier', 'françois', 'legault', 'says', 'government', 'must', 'consider', 'all', 'options', 'to', 'curb', 'spread', 'of', 'COVID-19,', 'including', 'extending', 'winter', 'holiday', 'break', 'in', 'international', 'force', 'peace', 'agreement', 'said', 'eight', 'were', 'killed', 'when', 'one', 'its', 'crashed', 'during', 'a', 'mission', \"egypt's\", 'number', 'COVID-19', 'cases', 'per', 'day', 'on', 'rise', 'states,', 'and', 'deaths', 'from', 'climbing', 'federal', 'has', 'plans', 'help', 'more', 'people', 'living', 'hong', 'kong', 'come', 'canada', 'as', 'chinese', 'down', 'pro-democracy', 'movement', 'may', 'have', 'broken', 'law', 'protests', 'RCMP', '@cattunneycbc', 'A', 'nova', 'scotia', 'man', 'launched', 'lawsuit', 'against', 'organization', 'runs', 'guatemalan', 'where', 'he', 'others', 'abused', 'for', 'years.', 'knew', 'it', 'was', 'wrong', 'her', 'sister', 'with', 'yet', 'she', 'went', 'great', 'cover', 'up', 'this', 'information.', 'canadians', 'deserve', 'better', 'their', 'elected', '—', 'conservative', 'ethics', 'critic', 'michael', 'barrett.', '@AshleyBurkeCBC', 'U.S.', 'food', 'drug', 'administration', 'approved', 'promising', 'antibody', 'therapy', 'scientists', 'treat', 'mild', 'moderate', 'coronavirus', 'infections.', '@JPTasker', '\"There', 'no', 'time.', 'we', 'act', 'now.', 'need', 'something', 'strong', 'mandatory', 'order', 'dr.', 'windsor', 'regional', 'hospital', 'CEO', 'david', 'drove', 'pick', 'medication', 'an', 'ICU', 'patient', \"didn't\", 'enough', 'stock', 'available', 'typhoon', 'vamco', 'rivers', 'flooded', 'areas', 'passed', 'over', 'northeastern', 'two', 'million', 'are', 'without', 'power', 'metro', 'surrounding', 'area.', 'told', 'pay', 'balance', 'after', 'speaking', 'someone', 'virgin', 'mobile', 'about', 'expensive', 'president-elect', 'joe', 'biden', 'appointed', 'top', 'democratic', 'official', 'ron', 'klain', 'his', 'chief', 'staff.', 'charge', 'obama', \"administration's\", 'response', 'health', 'crisis', 'independent', 'customers.', 'And', \"they're\", 'advocates', 'refugees', 'say', 'step', 'efforts', 'fleeing', 'conflict', 'persecution', 'abroad', 'despite', 'lockdowns', 'travel', 'restrictions.', '@OttawaReporter', 'opposition', 'staged', 'final', 'defiance', 'legislature', 'before', 'protest', 'four', 'tear', 'every', 'remembrance', 'thinking', 'what', 'soldiers', 'some', 'epidemiologists', 'already', 'project', 'ontario', 'surpass', '2,000', 'early', '@CBCQueensPark', 'james', 'gates', 'song', 'keep', 'written', 'imagines', 'point', 'view', 'would', 'fears', 'transmission', 'around', 'st.', 'really', 'set', 'into', 'motion', 'first', 'toobin', 'also', 'leave', 'position', 'legal', 'analyst', 'CNN.', \"province's\", 'newest', 'public', 'sets', 'maximum', 'indoor', 'outdoor', 'gathering', 'size', 'five', 'people,', 'agency', 'own', 'authority', 'not', 'nations', 'do', 'things,', 'expert', 'says.', 'restrictions', 'could', 'include', 'things', 'like', 'capacity', 'limits', 'services', 'activities', 'among', 'them', 'nearly', '200', 'queens', 'had', 'potential', 'start', 'there', 'parade', 'few', 'but', 'still', 'olympic', 'hopeful', 'development', 'rapid', 'testing', 'vaccines', 'novel', 'ensure', 'summer', 'games', 'can', 'successfully', 'take', 'place', 'tokyo', 'next', 'year,', 'starting', 'july', 'toward', 'dropped', '29', 'cent', 'pre-pandemic', '21', 'border', 'get', 'discovery', 'conservation', 'creatures', 'britney', 'asked', 'court', 'father', 'return', 'role', 'sole', 'global', 'management', 'agreed', 'share', 'company', 'price', 'very', 'good', \"here's\", 'latest', 'how', 'rest', 'world.', 'success', 'keeping', 'rates', 'low', 'change', 'coming', 'weeks,', 'according', '@TO_jwo', 'newly', 'confirmed', 'infections', 'push', 'seven-day', 'average', 'daily', 'highest', 'been', 'any', 'pandemic.', 'former', 'parks', 'manager', 'anonymous', 'restaurants', 'grocery', 'private', 'ceremonies', 'being', 'planned', 'long-term', 'care', 'facilities', 'home', \"canada's\", 'oldest', 'many', 'whom', 'particularly', 'high', 'risk', 'COVID-19.', 'centre', 'be', 'spot', 'police', 'community', 'groups', 'drop', 'off', 'person', 'overnight', 'instead', 'sending', '15', 'lawmakers', 'following', 'move', \"region's\", 'fellow', 'storms', 'longer', 'ocean', 'expert.', '@NebulousNikki', 'death', 'toll', 'again', 'begun', 'rise,', 'than', '600', 'since', 'late', 'august,', 'half', 'which', 'occurred', 'just', 'three', 'weeks.', 'who', 'should', 'vaccine', 'extremely', 'challenging', 'data', '@adamsmiller', '\"It', 'so', 'said,', 'through', 'face', 'mask.', 'WATCH', 'LIVE', '|', '2020:', 'CBC', 'news', 'special', '⚡️', 'made', 'covered', 'took', '300', 'hours', 'our', 'annual', 'going', 'virtual', 'way', 'make', 'experience', 'deeper', 'future', '@Murray_Brewster', 'rice', 'protests.', 'now', 'they', 'both', 'veterans', 'second', 'world', 'war.', 'fox', 'offensive', 'remarks', 'those', 'trump.', 'chose', 'toronto', 'because', 'enthusiasm', 'demand', 'seeing', 'users', 'country,', 'executive', 'scott', \"tuesday's\", 'numbers', 'continue', 'phase', 'largely', 'lower', 'strict', 'guidelines', 'place.', 'hundreds', 'died', 'air', 'strikes', 'fighting', 'escalating', 'fear', 'civil', 'war', 'given', 'deep', 'between', 'prime', 'minister', 'abiy', 'comes', 'largest', 'ethnic', 'group.', 'initiative', 'provides', 'opportunity', 'used', 'same', 'or', 'measures', 'under', 'section', '22', 'city', 'require', 'meeting', 'event', 'halls', 'other', 'remain', 'massive', 'explosion', 'port', 'district', 'tonnes', 'buildings', 'within', 'killing', 'injuring', 'justices', 'heard', 'arguments', 'appeal', 'coalition', '20', 'states', 'california', 'york', 'house', 'representatives', 'hoping', 'preserve', 'doctors', 'health-care', 'workers', 'warning', 'hospitals', 'able', 'handle', 'rising', 'cases.', 'staffers', 'employees', 'them,', 'appearances', 'publicly', 'work.', 'amazon', 'fines', 'billion', 'US', 'faces', 'antitrust', 'pompeo', 'ignored', 'results', 'showing', 'won', 'election,', 'dismissed', 'questions', 'whether', 'lost', 'judge', 'election', 'president', \"trump's\", 'claims', 'fraud', 'polls.', 'statement', 'officials', 'reporting', 'called', 'country.', '\"We', 'truly', 'fight', 'officer', 'brent', 'tuesday', 'morning', 'announcement', 'brian', 'total', 'includes', 'consecutive', 'well', 'peel', 'region,', '100', '72', 'region', '50', 'NDP', 'leader', 'singh', 'thinks', 'basic', 'income', 'pilot', 'newfoundland', 'labrador', 'fuel', 'national', 'program.', \"it's\", 'interim', '1', 'trial.', \"he's\", 'last', 'him', '32', 'months', 'clear', 'name.', 'alberta', 'calling', 'two-week', 'lockdown', 'stricter', 'homes', 'repeatedly', 'violated', 'provincial', 'rules.', \"peru's\", 'martin', 'vizcarra', \"country's\", 'congress', 'corruption', 'update:', 'trudeau,', 'address', 'defence', 'staff', 'general', 'asking', 'join', 'campaign', 'award', 'victoria', 'cross', '\"to', 'soldier', 'you', 'university', 'professor', '$1', 'gold', 'work', '@mle_chung', '#Analysis', 'committed', 'climate', 'change.', 'pressure', 'more.', '73', 'years,', 'john', 'visited', 'grave', 'belonging', 'fallen', 'immigration', 'lawyer', 'pandemic,', 'alternative', 'solutions', 'migrant', 'detention', 'easily', 'don', 'mortgage', 'buyers', 'bad', 'interest', '2020', 'prize', 'awarded', 'collection', 'remove', 'parts', 'voters', 'chance', 'polls', '9', 'a.m.', '8', 'p.m.', 'friday.', 'monday,', 'witnesses', 'support', 'known', 'bill', 'believed', 'always', 'represents', 'values,', 'regardless', 'why', 'wear', 'it.', 'believe', 'conversation', 'choice', 'prolonged', 'signed', '70', 'Nagorno-Karabakh', 'control', 'armenian', 'forces', 'backed', 'armenia', '1994', 'truce', 'ended', 'estimated', '30,000', 'died.', 'deal', 'monday', 'sell', 'partnership', 'premium', 'brands', 'british', 'columbia', 'briefing', 'weekend', 'sweeping', 'vancouver', 'coastal', 'regions', 'period', 'surge.', 'list', 'compiled', 'eligible', 'people.', 'recall', 'covers', 'certain', 'versions', '2018', 'expected', 'dec.', 'storm', 'likely', 'marks', 'beginning', 'trump', 'conceded', 'claiming', 'evidence', 'conspiracy', 'democrats', 'vote', 'tally', \"biden's\", 'analysis', 'far', 'looked', 'seven', 'days', 'pfizer', 'look', '14', 'adds', 'uncertainty', 'transition', 'nov.', '3', 'vote.', 'refused', 'concede', \"week's\", 'biden,', 'jan.', 'bar', 'association', 'nothing', 'lawyers', 'making', 'financial', 'various', 'political', 'donations', 'selection', 'test', 'positivity', 'rate', 'manitoba', 'rose', 'these', 'men', 'reported', 'alleged', 'He', 'Now', 'justin', 'trudeau', 'spoke', 'today', 'shared', 'battle', 'attorney', 'conducting', 'criminal', 'investigation', 'donald', 'Trump', 'defamation', 'women', 'accuse', 'sexual', 'liberal', 'spend', 'dollars', 'connect', 'most', 'high-speed', 'internet', 'UPDATE:', 'approval', 'process', 'confidence', 'safe', 'effective.', 'markets', 'result', 'elections,', 'saw', 'democrat', 'win', 'presidency.', \"pfizer's\", 'trial', 'secured', 'millions', 'said.', 'bright', 'filed', 'whistleblower', 'complaint', 'alleging', 'job', 'allow', 'widespread', 'use', 'hyperloop', 'completed', \"world's\", 'passenger', 'ride', 'pod', 'system,', 'executives', 'hit', 'speeds', 'las', 'kids', 'phone', 'handling', 'increased', 'even', 'difficult', 'demands', 'tropical', 'eta', 'landfall', 'key', 'sunday', 'night,', 'leaving', 'scores', 'dead', 'missing', 'mexico', 'central', 'america.', '#Analysis:', 'radio', 'host', 'topped', 'supporters', 'skeptical', 'progressive', 'policies', 'environment,', 'economy', 'abortion.', '@markgollom', 'airline', 'industry', 'contingent', 'providing', 'passengers', 'whose', 'flights', 'cancelled', 'suggests', 'shots', '90', 'effective', 'preventing', \"doesn't\", 'mean', 'woman', 'officers', 'prison', 'heading', 'supreme', 'aiming', 'end', 'practice', 'halifax', 'students', 'raised', 'thousands', 'victims', 'mass', 'shooting', 'while', 'walking', 'route', 'aides', 'allies', 'acknowledged', 'privately', 'fights', 'best', 'outbreak', 'infected', '11', 'residents', 'report', 'cases,', 'family', 'members', 'out', 'B.C.', 'focus', 'social', 'group', 'exercise', 'decisions', 'united', 'recorded', 'million,', 'seen', 'ont.', 'rallied', 'weekend.', 'came', 'observers', 'see', 'prince', 'william', 'changes', 'him.', \"georgia's\", 'so-called', 'state,', 'reliable', 'republican', 'presidential', 'wake', 'real', 'estate', 'experts', 'search', 'space.', 'foreign', 'affairs', 'advance', 'theresa', 'tam', 'noted', 'several', 'accelerated', 'schools', 'spent', 'trying', 'sort', 'quality', 'issues.', 'prove', 'another', 'challenge.', 'hockey', 'night', 'icon', 'NHL', 'star,', 'age', 'falling', 'short', 'diversity', 'numbers.', 'TV', 'alex', 'trebek', 'long', 'career', 'back', 'years', 'listed', 'upcoming', 'ban', 'single-use', 'celebrations', 'weakened', 'put', 'plans.', 'BREAKING:', '80', 'edmonton', 'heavy', 'saturday.', 'couple', 'left', 'brunswick', 'gained', 'media', 'never', 'go', 'away.', 'mark', 'nation', '@Alex_Panetta', 'trees', 'shows', 'viewers', 'tree', 'bitter', 'hot', 'days,', 'obstacle', 'tweet', 'led', 'actor', 'ryan', 'arctic', 'space', 'station', '40', 'ago,', 'ken', 'record,', 'named', 'red', 'sunday,', 'sun', 'showed', 'up.', 'sure', 'exactly', 'happened', 'theories.', '13-year-old', 'elliott', 'ont.,', 'launching', 'reading', 'service', 'proposed', 'drivers', 'downtown', 'critics', 'hurt', 'tiny', 'alaska,', 'attend', 'school', 'actually', 'getting', 'does', 'winnipeg', 'warn', 'introducing', 'curfew', 'amount', 'play', 'love', 'received', 'island', 'until', 'budget', 'sign', 'doug', 'ford', 'letting', 'coverage:', 'addresses', 'americans', 'time', 'star', 'paul', 'lee', 'emotional', 'moment', 'costume', 'once', 'nation,', 'cities', 'worst', 'infection', 'canada.', \"can't\", 'assume', \"won't\", 'become', 'again.', '@AaronWherry', 'quickly', 'turn', 'surge', 'least', 'prevent', 'worse.', 'looks', 'forward', 'building', 'relationship', 'biden.', 'crossed', '270', 'electoral', 'college', 'votes', 'pennsylvania.', 'documents', 'obtained', 'news,', 'patients', 'intensive', 'units', 'friday', 'june.', 'america', 'wins', 'election.', 'state', 'results.', 'politics,', 'energy', 'firms', 'jobs', 'struggling', '@KyleBakx', '@TonySeskus', 'mail-in', 'ballots', 'slim', 'margins', 'candidates', 'contributed', 'delay', 'winner.', 'pays', 'voter', 'here', 'answers', 'your', 'questions.', '37', 'registered', 'voters,', 'though', 'turnout', 'suffer', 'recent', \"there's\", 'turned', 'beat', '26', 'friday,', '28', 'care.', '\"People', 'sitting', 'room', 'watching', 'movie', 'typically', 'wearing', 'masks', 'usual', 'protocols', 'series', 'turner', 'pulled', 'game', 'tested', 'positive', '\"There\\'s', 'generation', 'along', 'maybe', \"don't\", 'idea', 'lot', 'if', 'japanese', 'discovered', 'middle', 'record', 'little', 'bit', 'chaotic', 'COVID', 'elections.', 'changing', 'market', 'recovery', 'slows', 'october,', 'only', 'jobs.', 'added', 'smallest', 'began', 'month.', 'FBI', 'virginia', 'tip', 'philadelphia', 'police.', 'timeline', 'warns', 'doses', 'supply', 'first.', 'presidency', 'might', 'relations', 'russia', 'appeared', 'propaganda', 'based', 'whole', 'foods', 'poppies', \"weren't\", 'allowed', 'recently', 'updated', 'policy,', 'affects', 'locations', \"wouldn't\", 'rejected', 'requests', 'minneapolis', 'charged', 'george', \"floyd's\", 'death,', 'ordered', 'tried', 'together', 'airlines', 'schedule', 'tens', 'monthly', 'cancel', 'vast', 'majority', 'weeks', \"It's\", 'strategy', 'distributing', 'free', 'cannabis', 'However,', 'concerned', 'stop', 'using', 'opioid', 'addiction', 'treatment.', 'places', 'enormous', 'support.', 'fact', \"pennsylvania's\", 'county', '2016', 'explain', 'born', 'leads', 'pennsylvania', 'conference', 'important', 'unfold', \"he'll\", 'illegal', 'businesses', 'The', 'mr.', 'claimed', 'responsible', 'losses', 'suffered', '2008', 'outbreak.', '#Opinion:', 'judges', 'neither', 'nor', 'ultimately', 'saying', 'is,', 'be.', 'figure', 'means', 'fewer', 'paid', 'did', 'animals', 'change,', 'MPs', 'sides', 'growing', 'online', 'security', 'threats', 'directed', 'public.', 'wait', 'numbers,', 'jerome', 'powell', 'suggested', 'burden', 'cannot', \"fed's\", '@don_pittis', 'month', 'started', 'candidate', 'ground', 'battleground', 'georgia', 'MP', 'parliament', 'bring', 'existing', 'suicide', 'prevention', 'looking', 'ways', 'meet', 'targets', '2030', \"aren't\", 'broke', 'season', 'blue', 'detailed', 'case', 'due', 'technical', 'problems', 'unclear', 'slipped', 'letter', 'door', '\"The', 'situation', 'shocking', 'needs', 'bonnie', 'henry', 'deaths,', 'active', 'risen', 'multiple', 'studies', 'shown', 'light', 'found', 'streets', 'affect', 'migration', 'august', 'fall', 'season,', 'production', 'season.', 'elections', 'spokesperson', 'having', 'nonpartisan', 'oversee', 'removes', 'politics', 'voting', 'process.', 'small', 'amid', 'wave', 'tax', 'announce', 'direct', 'funding', 'billions', 'aid', 'helped', 'replace', 'manage', 'costs', 'companies', 'facing', 'revenue', 'limit', 'puts', 'strain', 'cinemas', 'areas.', 'officially', 'paris', 'deal,', 'pact', 'countries', 'temperature', 'increases', 'below', 'century.', 'delayed', 'almost', 'handful', 'maintains', 'lead', 'experts,', 'intervene', 'stage', 'seemed', 'pollsters', 'seem', 'know', 'counted.', 'germany', '20,000', 'day,', 'level', 'yet.', 'israel', 'village', 'occupied', 'west', 'such', '\"I', 'think', 'meant', 'arm', 'GM', 'pickup', 'truck', 'assembly', 'plant', 'labour', 'union', '@p_evans', 'PHOTOS:', 'off.', 'town', 'bracing', 'rally', 'england', 'entering', 'requiring', 'non-essential', 'venues', 'restaurants,', 'stores', 'selling', 'clothing', 'boy', 'round', 'searches', 'stem', 'cell', 'save', 'life.', 'crusade', 'cut', 'spending', 'biggest', 'deficit', 'history.', 'climbed', 'all-time', 'day.', 'major', 'exceeded', '100,000', 'store', 'call', 'recommended', 'filter', 'mask,', 'bought', 'shopping', 'telescope', 'B.C.,', 'astronomers', 'powerful', 'fast', 'presence', 'team', 'philadelphia,', 'dozens', 'protesters', 'ready', 'down,', 'highlighted', 'tensions', 'counting', 'votes.', 'engaged', 'flurry', 'recount', 'wisconsin', 'filing', 'lawsuits', 'pennsylvania,', 'michigan', 'georgia.', 'economists', 'worry', 'divide', 'dire', 'economic', 'destined', 'follow', '2018,', 'canada,', '13', 'lives', 'coal', 'taken', 'line.', 'angry', 'vote-counting', 'centers', 'detroit', 'phoenix', 'returns', 'states.', 'moved', 'closer', 'victory', 'race', 'wisconsin.', 'danish', 'mutation', 'virus', 'became', 'S&amp;P', '500', 'dow', 'jones', 'industrial', 'afternoon', 'nasdaq', 'fared', 'better.', 'begins', 'count', 'workplace', 'declared', 'linked', \"'It\", 'makes', 'us', 'accurate', 'picture', 'reached', 'parties', 'provide', 'rent', 'relief', 'fashion', 'designer', 'bid', 'quest', 'over.', 'posted', 'himself', 'twitter', 'front', 'map', 'families,', \"shouldn't\", 'term', \"we're\", 'tackling', 'want', 'falsely', 'apply', 'week.', 'extra', 'required', 'ambassador', 'previously', 'flow', 'goods', 'statistics', 'lies', 'ahead.', 'rules', 'governing', 'ballots,', 'causing', 'delays', 'access', 'numerous', 'observe', 'opening', 'ballots.', 'anyone', 'less', 'popular', 'watchdog', 'information', 'mayor', 'threatened', 'divided', 'masks.', 'chair', 'task', 'efficacy', 'safety', 'advanced', 'investigating', 'rare', 'flu', 'detected', 'There', '27', 'influenza', 'expressing', 'concern', 'threshold', 'tightening', 'hardest-hit', 'too', 'high.', 'single', '\"murder', 'advised', 'hurricane', 'continues', 'spin', 'caribbean', 'coast', 'much', 'tuesday,', 'setting', 'deadly', 'landslides', 'ballot', 'proposal', 'uber', 'status', 'rather', 'employees.', '7', 'remained', 'morning.', 'course,', 'causes', 'carbon', 'emissions', 'car', 'earth', 'times.', 'formally', 'agreement,', 'promise', 'six', 'states:', 'nevada,', 'georgia,', 'arizona,', 'michigan,', '@EricGrenierCBC', 'miss', 'chips', 'packages', 'possible', 'glass', 'oregon', 'possession', 'amounts', 'street', 'drugs', 'relaxed', 'huawei', 'suing', 'agencies', 'try', 'release', 'believes', 'reveal', 'behind', 'arrest', 'post-election', 'aftermath', 'october', 'september.', 'resort', 'buy', 'triple', 'lift', 'created', 'lottery', 'them.', 'cold', 'weather', 'mental', 'test,', '5', 'prepare', 'reports', 'close', 'expressed', 'optimism', 'tight', 'ongoing', 'counts', 'swing', 'shares', 'trading', 'hands', '$15', 'opened', 'above', 'takeover', 'offers', 'investors', 'offer', 'ward', 'served', 'flight', 'royal', 'american', 'continued', 'wednesday', 'winner', 'declaration', 'race.', 'thank', 'joining', 'coverage', 'find', 'here:', 'prospects', 'fiscal', 'stimulus', 'recover', 'americans.', 'wisconsin,', 'coast,', 'races', 'contested', 'north', 'carolina,', '\"This', 'large', 'drives', 'challenge', 'poll', 'surveyed', 'system', 'marked', 'hand', 'maintaining', 'physical', 'distance', 'part', 'sustained', 'urging', 'stay', 'home,', 'live', 'appear', 'site', 'in,', 'president,', 'senate', 'house.', 'winds', 'kilometres', 'center.', 'U.S.,', 'recommendations', 'undermined', 'officials.', 'history,', 'ottawa', 'policy', 'streaming', 'platforms', 'operate', 'faced', 'traditional', 'jason', 'listen', 'advice', 'main', 'opponents', 'ivory', 'boycotted', 'recommending', 'choose', 'intended', 'clarity', 'level.', 'gain', 'senate,', 'flip', 'depending', 'presidency,', 'vice-president', 'deciding', 'monitoring', 'urged', 'additional', 'single-day', 'province.', 'regulators', 'critical', 'reaching', 'virus.', 'teams', 'division', 'option', 'considered', 'erin', \"O'Toole\", 'conservatives', 'requirements', 'flexible', 'simply', 'open', 'lose', 'training', 'bias', 'internal', 'showdown', '2000', 'lessons', \"today's\", 'life', 'construction', 'raise', 'build', 'down.', 'She', 'months,', 'away', 'young', 'girl', 'rescued', 'rubble', 'collapsed', 'izmir,', 'earthquake', 'seasonal', 'type', 'depression', 'brought', 'winter,', 'that’s', 'produced', 'unusual', 'moments', 'windows', 'white', 'children', 'got', 'haul', 'distance.', 'initial', 'eastern', 'braces', 'long,', 'dark', 'winter.', 'rainfall', 'predicted', 'region.', 'awards', \"children's\", 'book', 'human', 'rights', 'area', 'attackers', 'targeted', 'gives', 'shut', '31', 'dam', 'block', 'road', 'near', 'rural', 'bodies', 'fourth', 'injured', 'secure', '2016,', 'moving', 'jimmy', 'wife', 'kelly', 'peaceful', 'loses', 'that,', 'trump,', 'anything', 'robot', 'tend', 'considering', 'survive', 'member', 'household', 'symptoms', 'entire', 'transport', 'detect', 'endangered', 'atlantic', 'right', 'whales', 'interior', 'vienna', 'synagogue', 'terror', 'attack.', \"B.C.'s\", 'voted,', 'historic', 'rocky', 'mountains', 'preparing', 'plan', 'giving', 'imposing', 'bloc', 'blanchet', 'doubling', 'draw', 'line', \"party's\", 'values', 'concession', 'kept', 'diagnosis', 'secret', 'alarm', 'newspaper', 'reported.', 'pressed', 'waiting', 'gunmen', 'stormed', 'kabul', 'hosted', 'fair', 'attended', 'iranian', 'spokesman', 'involved', 'killed.', 'voluntarily', 'taking', 'review', 'rideau', 'toxic', 'culture.', \"That's\", 'readers', 'send', 'new,', 'protect', 'full', 'patients.', 'remains', 'favourite', 'chances', 'hillary', 'ago.', 'Donald', 'pull', 'ruled', 'johnny', 'depp', 'libel', 'owner', 'defendants', 'published', 'rescue', 'girls', 'alive', 'apartment', 'turkish', '21,', 'stand', 'charges', 'assault', '2017', 'floor', 'alcohol', 'system.', 'note', 'prepared', 'earlier', 'year', 'deputy', 'greater', 'intelligence', 'here,', 'gathered', 'family,', 'friends', 'colleagues', 'honour', 'formula', 'driver', 'lewis', 'hamilton', 'grand', 'different', 'nine', 'finally', 'train', 'tell', 'coronavirus,', 'story.', 'consumer', 'germany,', 'avoid', 'travel.', 'crown', 'washington', \"isn't\", 'impact', 'processes', 'determine', 'disease', 'dawn', 'equivalent', 'category', 'boris', 'johnson', 'current', 'threaten', 'overwhelm', 'laid', 'difference', 'children.', 'outcome', 'networks', 'soon', 'call.', 'dinner', 'local', 'cult', 'slew', 'journalists', 'slowing', 'past', '24', 'began.', 'finance', 'orbit', 'earth.', 'trail', 'territory', 'permanent', 'daylight', 'halloween,', \"nation's\", 'capital,', 'bringing', \"city's\", 'respects', 'intense', 'rains', 'capital', 'appears', 'mailed', 'arrived', 'later,', '2020.', 'finds.', 'arrested', 'male', 'suspect', 'stabbings', 'injured,', 'sent', 'crashing', 'province,', 'hospitalized', 'fire', 'chris', 'decided', '2018.', 'gatherings', 'learned', 'southwestern', 'bank', 'governor', 'widened', 'reducing', '8,000', 'medical', 'woods', 'business', 'owners', \"they've\", 'shot', 'military', 'essential', 'shops', 'close,', 'rebecca', 'careful', 'immune', 'knows', 'strictest', 'measures.', 'board', 'receive', 'regular', 'rate,', 'ends', 'hour', 'sleep', 'disruption', 'worth', 'it?', 'reputation', 'economy.', 'prospect', 'big', 'halloween', 'watch', 'movies', 'it,', 'run', 'mind', 'events', 'distancing,', 'drive-in', 'florida.', 'antibodies', 'scottish', 'sean', 'connery,', 'bond', 'threatening', 'bob', 'money', 'costumes', 'mississippi', \"she's\", 'politically', '2019.', '1,', 'advocate', '@cbcasithappens', 'felt', '\"the', 'recovered', 'earlier.', 'changed', 'bay', 'celebrates', \"hasn't\", 'suggest', 'golf', 'played', 'struggled', 'problem', 'worse', 'northern', 'P.E.I.', \"man's\", 'website', 'allows', 'visitors', 'read', 'reviews', '@trevorjdunn', 'mother', 'care,', 'protective', 'equipment', 'necessary', 'record.', 'stronger', 'labels', 'anxiety', 'looming', 'montreal', 'scrambling', 'warming', 'spaces', 'beds', 'airport', 'program', '12', 'projects', 'party', 'emergency', 'aim', '\"It\\'s', 'politics.', \"that's\", 'kind', 'nature', 'turning', 'updates', 'alert', 'app', 'exposure', 'date', 'actress', 'sentence', 'admissions', 'bribery', 'authorities', 'prison.', \"alberta's\", 'health,', 'outbreaks', 'ahead', 'neil', 'older', 'brother', 'released', 'third', 'enact', 'plastic', 'bag', 'SUV', 'identified', 'citizen', 'spreading', '@ybrend', 'thought', '17', 'sound', 'protected', 'marine', 'immigrants', 'jack', 'black', 'celebrities', 'ad', 'aimed', 'turkey,', 'greek', 'aegean', 'prompted', 'write', 'swift', 'action', 'coronavirus.', 'objections', 'commons', 'gave', 'easier', 'seek', 'assistance', 'london,', 'personal', 'worker', 'failed', 'handed', 'pet', 'investigators', 'attack', 'french', 'church', 'grew', 'domestic', 'product', 'But', 'overall', 'activity', 'february', 'sea', 'shaken', 'turkey', \"turkey's\", 'western', 'pushing', 'brink', '1,000', 'saskatchewan', 'finished', 'scored', 'victories', 'dry', 'basis', 'marketing', 'false', 'contained', 'trend', 'towards', 'haven’t', 'up.\"', 'narrow', 'my', 'I', 'meetings', 'reluctant', 'speak', 'language', 'expects', 'declines', 'increase', 'wells', '2021.', 'immediate', 'removal', 'taylor,', 'army', 'son,', 'peter', 'massachusetts', 'petition', \"year's\", 'representation', 'sri', 'director', 'funny', 'cameron', 'hospitalizations,', 'resident', 'law,', 'convicted', 'crime', 'holds', '10', 'serving', 'world,', 'guns', 'upon', 'accounting', '39', 'ruling', 'online,', 'justice', 'reality', 'allegations', 'abuse', \"state's\", 'continuing', 'calls', 'exports', 'medicine', 'prices', 'cancer', 'account', 'granted', 'request', 'privacy', 'mail', 'sunday.', 'population', 'researchers', 'study', 'party,', 'senators', 're-elected', '3.', 'quarter,', 'previous', 'one.', 'european', 'leaders', 'faith', 'digital', 'collected', 'images', 'recognition', 'technology', 'knowledge', 'commissioner', 'probe', 'trips', 'kenya', 'teachers', 'stress', 'related', 'finding', '@jonmontpetit', 'committee', 'stuck', 'WE', 'charity', 'coral', 'reef', 'barrier', 'healthy', '120', 'thursday,', 'france', 'fresh', 'inspire', 'path', 'growth', 'operations', 'shipping', 'giant', 'quarantine', 'fast-moving', 'zeta', 'louisiana', 'tank', 'argues', 'mix', 'competing', 'shifts', 'wreak', 'mountain', 'battles', 'then', 'emergence', 'nurses', 'influx', 'resurgence', 'hospitals.', 'attacker', 'armed', 'knife', 'nice,', 'It', 'france.', 'dog', 'week,', 'winners', 'projected', 'night.', 'reopening', 'tory', 'rights.', 'caught', 'water.', 'rock', 'popularity', 'TikTok.', 'responded', 'complaints', 'masks,', 'issues', 'heavily', 'longtime', '25', 'water', 'northwestern', 'clean', 'centres', 'zone', '30', 'treated', 'responders', 'stranded', 'friend', 'miles', 'taylor', 'working', 'department', 'combat', 'misconduct', 'tension', 'gripped', 'described', 'relatives', 'suffering', '2010', 'body', 'episode', 'long-running', 'closing', 'bars,', 'sharp', 'lockdowns,', 'governments', 'sought', 'tide', 'fill', 'demanding', 'behalf', '2015,', 'reporter', 'anchor', 'south', 'failure', 'inflation', 'gets', 'there.', 'ability', 'underway', 'elect', 'ads', 'widely', 'media.', 'answering', 'This', 'time,', 'testing.', 'offering', 'controversial', 'pages', 'medics', 'cast', 'mail.', 'terms', 'takes', 'declare', 'milestone', '10,000', 'That', 'though,', 'true', 'higher.', 'ties', 'platform', 'touch', 'dozen', 'senior', 'me', 'upset', 'are,', 'voters.', 'power.', 'trouble', 'president.', 'wetlands', 'designed', 'slow', 'examined', 'throughout', 'claim', 'superior', 'court,', 'alleges', 'oxford', 'properties', 'retail', 'breach', 'duty', 'natural', 'gas', 'river', 'reviewed', \"quebec's\", 'environmental', 'board,', 'however', 'worried', 'meng', \"ottawa's\", 'reduce', 'community.', 'effort', 'species', 'artists', 'denounced', \"president's\", 'collins,', 'disco', 'tom', 'office', 'contribution', 'doctor', 'author', 'shift', 'physician', 'verdict', 'delivered', 'writing', 'hearing', 'court.', 'hotel', 'bush', '35', 'kill', 'wolves', '\"an', 'waste', 'professional', 'raniere,', 'sex', 'keith', 'sentencing', 'convictions', 'female', 'followers', 'infectious', 'homeless', 'outdoors', 'inspired', 'research', 'london', 'protection', 'southern', 'edison', 'commission', 'sparked', 'tighter', 'uptick', 'merger', 'cuts', 'adding', 'alta.,', 'hope', 'mining', 'negative', 'consequences', 'right-wing', 'version', 'appearing', 'e-commerce', 'partner', 'TikTok', 'products', 'video-sharing', 'app.', 'hearings', 'crimes', 'suspects', \"government's\", 'eyes', 'signs', 'bomb', 'blast', 'ripped', 'islamic', 'northwest', 'pakistani', 'message', 'ignore', 'mandate', 'spring,', 'explaining', 'professionals', 'treatments', 'particular', 'odds', 'further', 'beyond', 'think,', 'file', 'stretched', 'anywhere', 'florida', 'forecasters', 'say.', 'reason', 'levels', 'places.', 'disputed', 'PM', 'crises.', 'brings', 'government,', 'vacant', 'resigned', 'august.', 'sports', 'hall', 'fame', 'closures', 'originally', 'lifted', 'thursday.', 'operators', 'andrew', 'studio', 'clients', 'depend', 'seized', 'naval', 'oil', 'tanker', 'english', 'channel', 'suspicion', 'asian', 'hornet', 'nest', 'trapped', 'surface', 'hidden', 'ice', 'NASA', 'held', 'today.', 'head', 'steady', 'climb', 'mask', 'eat', 'post', 'requested', 'devices', \"NASA's\", 'OSIRIS-REx', 'spacecraft', 'asteroid', 'grab', 'precious', 'particles', 'determined', 'washington,', 'question', 'accurately', 'azerbaijan', 'accusing', 'each', 'violating', 'ceasefire', 'enclave', 'Nagorno-Karabakh.', 'mike', 'pence', 'session', 'demanded', 'transportation', 'it’s', 'wind', 'year.', 'record-breaking', 'campaigning', 'combined', 'billion.', 'spanish', 'nationwide', 'hopes', 'nissan', 'battery', '2013', 'bike', 'nepal', 'display', 'entirely', 'trash', 'putting', 'funeral', 'business,', 'comfort', 'fundraising', 'restore', 'sits', 'park', 'now,', 'aims', 'battered', 'tone', 'legislative', 'signaling', 'gearing', 'campaign.', 'none', '19', 'lost,', 'boost', 'earnings', 'data.', 'princess', 'raising', 'concerns', 'spain', 'admitted', 'million.', 'hornets', 'property', '@sophiaharrisCBC', 'spike', 'straight', 'software', 'assess', 'warned', 'reasons', 'campaigns', 'jumped', 'student', 'chess', 'player', 'wireless', 'entrepreneur', 'guard', 'imposed', 'closure', 'compared', 'hard', 'suit', 'ask', 'veteran', 'himself.', 'poland', 'recording', 'problem.', 'influence', 'acting', 'priority', 'commercial', 'sector', 'foster', 'accept', 'cards', 'diagnosed', 'one-day', 'seeking', 're-election', 'later', 'understanding', 'challenges', 'secretary', 'democracy', 'integrity', 'snap', 'violates', 'constitution', 'act.', 'saturday,', '@bethanylindsay', 'programs.', 'skin', 'risks', 'parents', 'sanitizer', 'children,', 'theatre', 'begin', 'january', 'contract', 'aware', 'engines', 'expanding', '800', 'ships', 'disease,', 'track', 'currently', 'video', 'hollywood', 'remaining', 'force.', 'AstraZeneca', '&amp;', 'same.', 'demonstrations', \"nigeria's\", 'Anti-Robbery', 'unit', 'explore', 'plasma', 'severe', 'forecast', 'arrive', 'environment', 'celebrating', 'council', 'festival', 'combination', 'separated', 'border.', 'famous', 'sold', 'auction', 'US,', 'second-highest', 'ever', 'like,', 'bird', 'hate', 'suspected', 'symbol', 'unknown', 'election?', 'inform', 'coverage.', 'email', 'legislation', 'harder', 'refugee', 'country', 'youngest', 'toronto,', '@LaurenPelley', 'retailer', 'thursday', 'evening', 'ideas', 'imagine', 'point.', 'U.K.', 'EU', 'negotiations', 'last-minute', 'trade', 'tumultuous', 'envoy', 'lays', '“the', 'greatest', 'lead.', 'identify', 'workers,', 'distant', 'countries,', 'image', 'brief', 'affordable', 'housing', 'especially', 'serious', 'reveals', 'repeat', 'amplified', 'marched', 'carrying', 'withstand', 'animal', 'rolled', 'toyota', 'studying', 'shell', 'teach', 'planes', 'buildings.', 'willing', \"island's\", 'So', 'SARS,', 'attempts', 'abuses', 'holding', 'advantages', 'shortage', 'cash', 'and,', 'hiring', 'staff,', 'establishing', 'creating', 'plan,', 'agrees', \"china's\", 'meets', 'definition', 'genocide', 'unveiled', 'spring', 'works', 'offered', 'land', 'crossing', 'calgary', 'picked', 'speed', '14th', 'century', 'century,', 'EU,', 'merely', 'mount', 'temperatures', 'days.', 'debate', 'carried', 'ET.', 'itself', 'tim', 'burger', 'king', 'customers', 'minnesota', 'murder', 'knee', 'second-degree', 'judiciary', 'voted', 'favour', 'nomination', 'amy', 'coney', 'barrett', 'Democrats', 'elementary', 'learn', 'residential', 'education', 'korean', 'links', 'hill', '2014', 'gunman', 'astronaut', 'landed', 'provinces', 'randi,', 'escape', 'artist', 'challenged', 'regarded', 'fierce', 'winning', 'barack', 'views', 'philadelphia.', 'rudy', 'giuliani', 'featured', 'borat', 'scene', 'formal', 'crackdown', 'demonstrating', 'nigerian', 'cities,', 'feared', 'accused', 'controls', 'senate.', 'race,', 'pieces', 'helping', 'effects', 'contain', 'memoir', 'series.', 'intends', 'june', 'hotly', 'progress', 'registration', 'iran,', '1980s', 'tackle', 'caused', 'opposed', 'barrett,', 'appeals', 'confirmation', 'expand', 'judicial', 'records', 'wednesday,', '@sarahcrgr', 'iran', \"iran's\", 'aviation', 'met', 'delegation', 'week', 'talks', 'figures', 'michigan.', 'postal', '4,000', 'employees,', 'vehicles', 'appearance', 'tonight', 'index', 'month,', 'restrictions,', 'criticism', 'approach.', 'teens', 'spring.', 'plea', 'effectively', 'paying', 'stopped', 'charging', 'purdue', 'wealthy', 'advisers', 'chosen', '4', 'eliminate', 'give', 'preliminary', 'september', 'sales', 'running', 'ending', 'double', 'halt', 'pope', 'francis', 'endorsed', 'same-sex', 'unions', 'family.', 'corporate', 'cap', 'individuals', 'liberals', 'found.', 'representing', 'frustrated', 'families', 'google', 'moves', 'tech', 'giants', 'china', 'asia', 'expert,', 'U.N.', 'reach', 'disinformation', 'measure', 'backing', 'resources', 'expansion', 'assistant', 'olympics', 'significant', 'postponed', 'brutality', 'japan', 'routes', 'bill.', 'steadily', 'fake', 'encouraging', 'possible,', 'busy', 'freeze', 'nuclear', 'extend', 'arms', 'treaty', 'jeff', 'bridges', 'signature', 'voice', 'character', '\"As', 'sept.', 'launch', 'lobster', 'fishery', 'air,', 'application', '12,000', 'sued', 'dominance', 'advertising', 'competition', 'harm', 'seniors', 'staying', 'safe,', 'nursing', 'legitimate', 'wedding', 'included', 'valuable', 'turns', 'out,', 'professors', 'defending', 'colleague', 'suspended', 'class', 'failing', 'benefits', 'plunged', 'youth', 'programs', \"minister's\", 'playing', 'appointment', 'infections,', 'useful', 'probably', 'hardest', 'decision', \"i've\", 'pumpkin', 'crowned', 'weighed', 'ski', 'condition', 'statue', 'T.', 'times', 'larger', 'summer.', \"sweden's\", 'approach', 'advocacy', 'wants', 'conversations', 'vulnerable', 'shutting', 'helicopter', 'fireworks', 'effect', '1.', 'damage', 'musician', 'degrees', 'interests', 'music', 'mind.', 'usually', 'fly', 'hotels', 'rates,', 'bus', 'classes', 'home.', 'shifting', 'responsibility', 'dealing', 'anthony', 'fauci', 'agree', 'mostly', 'uncertainty,', 'survey', 'november,', 'indictment', 'unsealed', 'russian', 'attacks', 'wide', 'range', 'champagne', 'wall', 'migrants', 'luis', 'left-wing', 'evo', 'morales', 'narrowly', 'resolution', 'funded', 'managed', '74', 'infected.', 'gary', 'league', 'fans', 'closed', 'countries.', 'revolution', 'weapon', 'original', 'selected', 'network', 'moon,', 'humans', '2024.', \"john's\", 'indigenous', 'miller', 'fishermen', 'impose', 'apart', 'messages', 'telling', 'compelling', 'stories', 'shaky', 'gaining', 'strength', 'consumers', 'auto', 'attacked', 'violent', 'crucial', 'tool', 'racism', 'shows.', 'blocking', 'thai', 'websites', 'removing', 'What', 'crews', 'fire.', 'widow', 'locked', 'apple', 'material', 'legally', 'cabinet', 'ministers', 'joined', 'hold', 'discuss', 'southwest', 'native', 'perfect', '700,000', 'counted', 'childhood', 'starts', 'engaging', 'wounded', 'UN', '\"a', 'momentous', 'name', 'monday.', 'not.', 'completes', 'contact', 'tracing', 'depends', 'texas', 'horse', 'physically', 'distancing', 'in-person', 'controversy', 'attention', 'Tuesday.', 'sample', 'reopen', 'oct.', 'however,', 'scheduled', 'story', 'two-thirds', 'laura', 'ones', 'love.', 'inside', 'treatment', 'not,', 'before.', 'distanced', 'dancing', 'normal', '15,', 'school.', 'done', 'switch', 'standard', 'healthier', 'edward', 'county.', 'complete', 'DNA', 'wildlife', 'estimate', 'herd', '2015', 'volunteers', 'apps', 'expect', 'resorts', 'doing', 'decades', 'pipeline', 'socially', 'ever.', 'on,', '60', 'transplant', 'zealand', 'jacinda', 'ardern', 'office.', 'polling', 'error', \"wasn't\", 'steps', 'happening', 'delivery', 'orders', 'govern', 'homes,', 'operation', 'fully', 'canada’s', 'now?', 'teenager', 'hear', 'leaders,', 'partners', 'systemic', 'healthcare', 'developed', 'school,', 'monitor', 'exams', 'mayors', 'capital.', 'san', 'lucky', 'opportunities', 'i’ve', 'anne', 'emails', 'tied', 'lived', 'son', 'fund', 'produce', 'involving', 'conducted', 'daughter', 'decades.', 'spotted', 'patrol', 'retired', 'argued', 'outdated', 'expecting', 'flying', 'shelves', 'burn', 'fossil', 'fuels', 'essentially', 'heat', 'institutions', '700', 'fifth', 'violence', 'harassment', 'fishing', 'mounted', 'sen.', 'ben', 'christian', 'antiviral', 'remdesivir', 'clinical', 'svetlana', 'fled', 'tape', 'visit', 'dying', 'visits', 'syndrome', 'boards', 'hybrid', 'model', 'remote', 'leading', 'doesn’t', 'retreat', 'drive', 'prayuth', 'chan-ocha', 'anti-government', 'defied', 'benefit', 'coping', 'measures,', 'wondering', 'sustainable', 'control.', 'maps', 'names', 'repair', 'industry.', 'investment', 'firm', 'market.', 'earned', 'tony', 'documentary', 'jury', 'mystery', 'refuses', 'gov.', 'gretchen', 'whitmer', 'kidnapping', 'plot', 'capitol', 'tonight,', 'debate,', 'temporarily', 'restricted', 'three-day', 'tour', 'bell', 'others,', 'As', 'today,', 'country’s', 'field', 'milwaukee', 'suburb', \"barrett's\", 'nomination.', 'grant', 'asylum', 'criticized', 'jerry', '1,500', 'dispute', 'capita', 'virtually', 'queen', 'elizabeth', 'wore', 'associated', 'kamala', \"harris's\", 'vice-presidential', 'refusing', 'customer', 'restaurant', 'september,', 'fiat', 'chrysler', 'electric', 'vehicle', 'economy,', 'boom', 'writes', 'thomas', 'marathon', 'revive', 'promised', 'november.', 'supposed', 'attending', 'networks.', \"thailand's\", 'banned', 'targeting', 'maha', 'providers', 'limited', 'supplies', 'rapidly', 'way.', '16', 'TikTok,', 'instagram', 'twitter.', 'fish', 'bear', \"who's\", 'facility', 'reaches', 'deliveries', 'box', 'drag', 'months.', 'habitat', 'outside', 'hospitalization', 'applications', 'issue', 'ten', '2016.', 'tourism', 'Nagorno-Karabakh,', 'ukraine', 'represent', 'group,', 'narrowing', 'window', 'deliver', 'issued', 'bank.', 'thailand', 'camp', 'melania', 'revealed', 'communications', 'hired', 'fallout', '18', 'feeling', 'points', \"tonight's\", 'debate.', 'huge', 'margin', 'overcome', 'pattern', 'senator', 'cheaper', 'antigen', 'tests', 'losing', \"haven't\", 'taxes.', 'NBC', 'opponent', '911', 'york,', 'prosecutors', 'debates', 'empty', 'isolation', 'inconsistent', 'pain', 'racist', 'photo', \"india's\", 'driven', 'establish', 'moon', 'maintain', 'trick-or-treating', 'accounts', 'match', \"russia's\", 'pose', 'disappointment', 'remember', 'although', 'rejecting', 'lockdowns.', 'placed', 'higher', 'design', 'orange', 'hospitalizations', 'outbreaks.', 'cleared', 'crowds', 'phones', 'faster', '5G', 'europe', 'succeed', 'package', 'chain', 'traced', 'respect', 'realities', 'BTS', 'leader,', 'settlement', 'smaller', 'rival', 'cuba', 'seats', 'saudi', 'arabia', \"women's\", 'cutting', 'metal', '1970s', 'ring', 'microsoft', 'disrupt', 'uses', 'computers', 'attempting', 'create', 'investigate', 'issue.', 'nominee,', 'declined', 'roe', 'v.', 'wade', 'properly', 'highly', 'extradition', 'affecting', 'rely', 'dogs', 'europe,', 'sick.', 'kidnap', 'detained', 'desperate', 'late-stage', 'paused', 'investigates', 'decades,', 'thanks', 'beach', 'jean', 'remembered', 'turmoil', 'exposed', 'ohio', 'map.', 'wanted', \"i'm\", 'revealing', 'china,', 'suburban', 'state.', 'grow', 'length,', 'mouth', 'consume', 'interview', 'london.', 'cities.', 'pleaded', 'guilty', 'ruth', 'bader', 'ginsburg', 'overwhelming', 'spots', 'defeating', 'miami', '6.', 'robert', 'nobel', 'economics', 'theory', 'married', 'era', 'folk', 'murphy', '19th', 'connected', 'variety', 'sharing', 'visions', 'landmark', 'filled', \"disney's\", 'completely', 'republicans', 'civilians', 'fired', 'second-largest', 'city.', 'normally', 'ethical', 'thanksgiving', 'own.', 'away,', 'poised', 'reports.', 'nearby', 'dreams', 'leaves', 'museum', 'alone', 'easy', \"korea's\", 'missile', 'crash', 'returned', 'performances', 'damaging', 'health.', 'insisted', 'rally.', 'concerning', 'come.', 'pakistan', 'blocked', 'receiving', 'concluded', 'transmitted', 'airborne', 'followed', 'flown', 'happens', 'purchase', 'wave,', 'blame', 'exchange', 'prisoners', 'dead,', 'diplomats', 'opera', 'falls', 'tricky', 'nashville,', 'on.', 'recommend', 'act,', 'city’s', 'tourist', '$1.8', 'ticket', 'add', 'acres', 'seeks', 'moral', 'hero', 'removed', 'musical', 'videos', 'green', 'alliance', 'says,', 'rich', 'poor', 'upheld', 'driving', 'vital', 'deny', 'spread.', 'hits', 'minister,', 'replaced', 'farmers', 'tools', 'east', 'Some', 'bubble', 'saturday', 'delta', 'unprecedented', 'sixth', 'prominent', \"what's\", 'stake', 'journalist', 'sanctions', 'list.', 'cautious', 'nominee.', 'reduced', 'bankruptcy', 'processing', 'bed', 'built', 'eating', 'illness', 'death.', 'reunited', '110', 'disease.', 'experimental', 'experiences', 'feel', 'visiting', 'rapper', 'los', 'angeles', 'deaths.', 'prizes', 'protecting', 'experienced', 'addressing', 'barriers', 'laws', 'daniel', 'wider', 'members.', 'details', 'brutal', 'lesson', 'modern', 'rhetoric', 'increasing', 'atmosphere.', 'gender', 'QAnon', 'netflix', '$2', 'attempt', 'serve', 'reminder', '\"I\\'m', 'navigate', 'literature', 'louise', 'beauty', 'individual', 'defended', 'harris', 'history', 'funds', 'goal', 'finish', 'urge', 'celebrate', 'soaring', 'concept', 'illegally', 'vice', 'machine', 'farm', 'derail', 'positions', 'unidentified', 'guy', 'battling', 'lung', 'cancer.', 'surgery', 'november', 'government.', 'nurse', 'facebook', 'weed', 'militants', 'britain,', 'ET', 'billionaire', 'barry', 'files', 'steve', 'generations', 'old', 'suddenly', 'subject', 'cost', 'argue', 'undermine', 'yucatan', 'dangerous', '2', 'storm.', 'recovery.', '3rd', 'jennifer', 'developing', 'method', 'victor', 'trust', 'unique', 'weighing', 'decade', 'impacted', 'studies.', 'speakers', 'convention', 'tasked', 'negotiating', 'throne', 'speech', 'passes', 'becomes', '2021,', 'changes.', '\"will', 'viral', 'sharply', 'chairman', 'joint', 'chiefs', 'gen.', 'eddie', 'van', '\"If', 'have,', 'university.', 'australian', 'mainland', 'there,', 'surging', 'smith', 'in.', 'fought', 'vaccine.', 'device', '2022.', 'needed.', 'evolved', 'newsletter:', 'internet.', 'side', 'tough', 'introduced', 'lab', 'tariffs', 'Joe', 'present', 'too.', 'ginsburg,', 'nominee', 'matt', 'incident', 'organizations', 'welcomed', 'jobs,', 'admits', 'extent', 'severity', 'refinery', 'protocols,', 'distancing.', 'saved', 'three-week', 'forms', 'express', 'contracting', 'confident', 'seat', 'burned', 'california.', 'syria', 'press', 'kayleigh', 'McEnany', 'test.', 'misleading', 'wrong.', 'gun', 'dead.', 'tactics', 'success.', 'die', 'employers', 'either', 'wages', 'birth', 'gyms', 'denied', 'him,', 'party.', '•', 'researcher', 'breaks', 'ground.', 'harvey', 'J.', 'charles', 'shark', 'duo', 'civilian', 'others.', 'denies', 'society', 'develop', 'beacon', 'leadership', 'banks', 'feed', 'accepted', 'quite', 'say,', 'job.', 'stronghold', 'raises', 'title', 'inner', 'circle', \"who've\", 'garden', 'matter', 'polar', 'visible', 'fell', 'ill', 'possibly', 'tips', 'bears', 'win.', \"they'll\", 'proving', 'silicon', 'valley', 'publish', 'bars', 'missed', 'work,', 'fall.', 'sense', 'leader.', 'market,', 'islands', 'minutes', 'ambulance', 'needed', 'E.', 'flood', 'soar', 'contest', '74,', 'factor', 'complications', 'bill,', 'screening', 'messaging', 'increasingly', 'lady', 'navy', 'direction', 'conduct', 'yorkers', 'rarely', 'frustration', 'resume', 'midst', 'chamber.', 'everything', 'extended', 'wife,', 'surveillance', 'hitting', 'walk', 'forest', 'respond', 'findings', 'CNN', 'aide', 'struggle', 'announces', 'word', 'contracted', 'quietly', 'embassy', 'experiencing', 'symptoms\"', 'lisa', 'murdered', 'His', 'killer', 'parole', 'unable', 'Here', 'activities.', 'what,', 'drew', 'instant', 'worldwide', 'reactions', 'swiss', 'boys,', 'By', 'afternoon,', 'attempted', 'clarify', 'proud', 'boys', 'release.', 'allowing', 'sit', 'educational', '400', 'maine', 'advantage', 'learning', 'batch', 'employee', 'authorities.', 'july.', 'then,', 'deemed', 'serves', 'distribution', 'child', 'contains', 'fancy', 'chrissy', 'teigen', 'husband,', 'loss', 'wrote', 'legend', 'france,', 'greenhouse', 'loss,', 'chanting', 'kits', 'fraud,', 'voting.', 'sick', 'brand', 'vatican', 'citing', 'strip', '\"is', 'often', 'alexei', 'navalny,', 'recovering', 'poisoned', 'nerve', 'vladimir', 'putin', '$10', 'infrastructure', 'initiatives', 'weigh', 'television', 'kingdom', 'schools,', 'spark', 'How', 'separate', 'italy', 'summer,', 'easing', 'introduce', 'rocket', '545', 'short-term', 'doubled', 'before,', 'tells', \"'the\", 'harsh', 'aside', 'parent', 'directly', 'underground', 'banking', 'survived', 'injuries', 'mac', 'davis', '78.', 'wednesday.', 'economies', 'responding', 'analyzed', 'here’s', 'taste', 'certainly', 'afford', 'feminist', 'anthem', 'am', 'woman,', 'For', 'jobless', 'challenger', 'accusations', 'britain’s', 'articles', 'universal', 'considers', 'dismiss', 'talk', \"'a\", 'dream', 'band', 'blow', 'estimates', 'enough.', 'reopened', 'urgent', 'sale', 'weekly', 'belarusian', 'alexander', 'employment', 'ease', 'populous', 'taxes', 'first-ever', 'glitches', 'humanitarian', 'crisis.', 'roughly', 'update', 'lines', 'policing', 'courts', '–', 'proceedings', 'breonna', 'raid', 'louisville', 'wildfires', 'destroyed', '7,000', 'complain', 'taught', 'let', 'fatally', 'head-to-head', 'televised', 'fine', 'absolutely', 'matters', 'diplomatic', 'taiwan', 'ago', 'spreads', 'immunity', '3,000', 'lifts', 'meals', 'italian', 'buried', 'minimum', 'planet', 'twin', 'crises', \"they'd\", 'participate', 'hall.', 'generated', 'cancer,', 'happen', 'lunar', 'At', 'attacks.', 'centuries', 'marriage', 'fires', 'erupted', 'famed', 'wine', \"california's\", 'county,', 'forcing', 'goes', 'poison', 'lake', 'facts', 'onto', 'affected', 'en', 'deadline', 'clearly', 'pass', 'case.', 'pregnancy', 'scale', 'doors', 'herself', 'ministry', 'analysis:', 'divisions', 'generally', 'basically', 'impossible', 'simple', \"you're\", 'teacher', 'nominated', 'seat.', 'deals', 'emmanuel', 'involves', '80.', 'retailers', 'rush', 'broad', 'posts', 'pacific', 'whale', 'baby', 'sources', 'surpassed', '150,000', 'january.', 'pounds', 'partly', 'government’s', 'pledge', 'web', 'demonstrators', 'swedish', 'three-quarters', \"queen's\", 'dual', 'meaning', 'muslim', 'hair', 'religious', 'complex', 'extends', 'tragedy', 'russia,', 'investigations', 'drawn', 'evangelical', 'hosts', 'GDP', 'posting', 'shutdowns', 'intentionally', 'seventh', 'supporting', 'performer', 'regulatory', 'blind', 'predicts', 'reporters', 'investments', 'cable', '\"He', 'insurance', 'expanded', 'normal.', 'activists', 'lukashenko', 'lacks', 'briefly', 'avert', 'that.', 'suppression', 'kinds', 'tame', 'korea', 'troops', 'tighten', 'mask-wearing', 'age.', 'commit', 'transfer', '\"We\\'re', 're-election.', 'delivers', 'chaos', 'promises', 'thousand', 'They', 'louisville,', 'can,', 'de', 'vote,', 'letters', 'presidents', 'teddy', 'logistical', 'limiting', 'tourists', 'forced', \"britain's\", 'constitution,', 'magic', 'form', 'credit', 'xi', 'environment.', 'burning', 'forests', 'mounting', 'actions', 'minority', 'highlights', 'dutch', 'startup', 'structure', 'australia', 'died,', 'waters', 'derek', 'nigeria', 'kentucky', 'unite', 'roberts', 'words', 'describe', 'german', 'treating', 'navalny', 'poisoning', 'gather', 'nation.', 'command', 'plenty', 'rain', 'self-isolate', 'awaiting', 'called.', 'encounter', 'april', 'warrant', 'courts.', 'payette', 'assist', 'fend', 'checks', 'creator', 'show,', 'pledged', '6', \"family's\", 'discussing', 'person.', 'painted', 'coffins', 'mall', 'company.', 'colleges', 'commitment', 'motor', 'petersburg', 'headed', 'journey', 'entry', 'extraordinary', 'legacy', 'carry', 'thing', 'visas', 'march', 'mitt', 'romney', 'control,', 'slammed', 'offices', 'life,', 'like?', 'pollution', 'factors', 'ranging', 'desert', 'southeast', 'approaches.', 'shootings', 'purchases', '900', 'team.', \"australia's\", 'large-scale', 'campus', 'painting', 'hospital.', 'square', 'delivering', 'together.', 'tapped', 'constitutional', 'addition', 'interfere', 'renewable', 'titles', 'NFL', 'connection', 'britain', 'unless', 'jersey', 'post-Brexit', 'anxious', 'lack', 'cloud', 'claims.', 'jonathan', 'surprisingly', 'comedy', 'completing', 'sweep', 'enforcement', 'containing', 'addressed', 'WeChat', 'amendment', 'airs', 'forget', 'fundamental', 'trauma', 'expands', 'cars', 'parking', 'crowd', 'equality', 'afghan', 'hangs', 'taliban', 'for.', 'politician', 'epidemic', 'immediately', '7.', 'edition', 'film', 'guidance', 'resource', 'diners', 'restaurants.', 'outstanding', 'casting', 'financing', 'highlight', 'pancreatic', 'july,', 'puerto', 'cyber', 'else', 'lots', 'food.', 'disabilities', 'treasury', 'uncovered', 'technologies', 'indian', 'Now,', 'roll', 'transactions', 'triggered', 'yet,', \"brazil's\", 'pantanal', 'prestigious', 'jim', 'worked', 'risk.', 'ambitious', 'vision', 'unfounded', 'fraud.', 'priorities', 'wish', 'chemical', 'provided', 'missions', 'robotic', 'probes', '50,000', 'stream', 'detroit,', 'barr', 'restrict', 'waited', 'birthday', 'bottle', 'novichok', 'agent', 'blamed', 'resulted', 'owned', 'shelter', 'politicians', 'One', 'help.', 'outlook', 'theories', 'possibility', 'violence.', 'threat', 'choice.', 'belarus', 'intimidation', 'iPhones', 'tests,', 'pop', 'stepping', 'approves', 'halted', 'positive.', 'trip', 'aged', 'belong', 'activist', 'agenda', 'step,', 'anybody', 'count.', 'populations', 'ultimate', 'capable', 'inquiry', 'fact-check', 'victim', 'hunter', 'dragged', 'sometimes', \"we've\", 'china.', 'ran', \"japan's\", 'yoshihide', 'suga', 'man.', 'plane', 'blames', 'boeing', '737', 'max', 'knowing', 'residence', 'sally', 'gulf', 'panel', 'audio', 'memorial', 'tribute', 'flooding', 'city,', 'blaze', 'slowed', 'source', 'longer.', 'representative', 'cited', 'championship', 'allegedly', 'improbable', 'smoke', 'covering', 'reforms', \"taylor's\", 'imports', 'unveil', 'rebuild', 'beirut', 'later.', 'flags', 'array', 'democracies', 'protects', 'liberty', 'diseases', 'diamond', 'types', 'out.', 'you.', 'discredit', 'wayne', 'commander', 'universities', 'majority,', 'twice', 'overhaul', 'supported', 'operating', 'established', 'trends', 'debt', 'sees', 'deeply', 'coach', 'viewed', 'found,', 'cemetery', '2020,', 'governors', 'rebel', 'week’s', 'strengthened', 'hurricane,', 'center', 'atmosphere', 'oxygen', 'deliberately', 'row,', 'attraction', 'know,', 'oracle', 'analysts', \"company's\", '23', 'wildfire', \"Here's\", 'stretch', 'boat', '17-year-old', 'graham', 'managing', 'pandemic?', 'raging', 'bureau', 'discarded', 'safer', 'returning', 'donated', 'franchise', 'weapons', 'resignation', 'overwhelmingly', 'designated', 'conditions', 'incorrect', 'headline', 'deleted', 'exploring', 'snow', 'begins.', 'grows', 'efficient', '2019,', 'opens', 'israeli', 'benjamin', 'netanyahu', 'bin', 'al', 'announcing', 'disposable', 'boston', 'creative', 'solution', 'hyundai', 'SUVs', '2019', 'fix', 'floyd', 'roles', 'rio', 'destruction', 'sites', 'register', 'catching', 'moria', 'notorious', 'mine', 'marking', 'bold', 'similar', 'fate', 'fraught', 'dangers', 'tennis', 'husband', 'seems', 'aggressive', 'lined', 'santa', 'reverse', '75', 'douglas', 'december', 'march.', 'loans', 'slower', \"'The\", 'afghanistan', 'greece', 'vary', 'founder', 'organized', 'wipes', 'string', 'survivors', 'extreme', 'hard-hit', 'target', 'classified', 'india', 'sexually', 'her.', 'diana', '1960s', 'style', 'portrayed', 'palestinian', 'absence', 'proved', 'promoted', 'emerged', 'defend', \"kong's\", 'fire,', 'devastated', 'california,', 'OK', 'spooky', 'halloween.', 'hanging', 'subsequent', 'stops', 'stars', 'successful', 'scientist', 'towns', 'tracking', 'improve', 'decade.', 'initially', '11th', 'kyle', 'poured', 'edged', 'reported,', 'finds', 'law.', 'pace', 'refusal', 'extension', 'project,', 'throw', 'pitch', 'swept', 'ranks', 'gone', 'encourage', 'screen', 'hydrogen', 'future,', 'lineup', 'shifted', 'trump’s', 'manufacturing', 'quick', 'cause', 'drawing', 'camps', 'standing', 'chef', 'thriller', 'understand', 'stocks', 'street,', 'momentum', 'apple,', 'epic', 'trigger', 'hood', 'regulations', 'ordering', 'volume', 'online.', '24.', 'output', 'catholic', 'aboard', 'maria', 'kolesnikova', 'All', 'racial', \"germany's\", 'longest', \"court's\", 'parliamentary', 'firearms', \"myanmar's\", 'rape', 'countless', 'rohingya', 'examining', 'art', 'debut', 'charlie', 'institute', 'charges.', 'staggering', 'killed,', 'mediterranean', 'net', 'CDC', 'sinovac', 'feature', 'screenings', 'stressful', 'emotionally', 'importance', 'football', 'flipping', 'houses', 'generate', 'began,', 'may.', 'january,', 'didn’t', 'brief:', 'drugs.', 'features', 'severely', 'lebanon', 'treasure', 'draws', 'late-night', 'roger', 'catch', 'mosque', 'bangladesh', 'communities', 'minds', 'themselves', 'brazil', 'hours.', 'ship', 'strike', 'stark', 'portland', 'arrests', 'blood', 'barely', 'planning', 'WHO', 'vaccinations', 'patience', 'thin', '45', 'weekend,', 'yes,', 'philippine', 'cargo', 'everyone', 'have.', 'tonight.', 'live.', 'stickers', '65', 'crew', 'signal', 'amazon,', 'tesla', 'quarter', 'february,', 'report,', 'archaeologists', 'safely', 'signals', 'beats', 'familiar', 'foreigners', 'entered', 'cinema', 'code', 'lets', 'becoming', 'disaster', 'landslide', 'balance,', 'kidney', 'reform', 'payments', 'cooperation', '85-year-old', 'brooklyn', 'comments', 'avoiding', 'restrained', 'vows', 'heads', 'cruise', 'storage', 'routinely', 'stolen', 'jurors', 'threats,', 'content', 'survival', 'hole', '66', 'solar', 'cook', 'dance', 'video,', 'blew', 'doubt', 'vaccine,', 'trials', \"york's\", 'metropolitan', 'futuristic', 'know:', 'drive-thru', 'hailed', 'marching', 'mixed', 'announced.', 'sizes', 'filling', 'polls,', 'surrounded', 'festival,', 'jacob', 'injustice', 'volunteer', 'jets', 'eric', 'precautions', 'alphabet', 'instead.', 'uncertain', 'house,', 'baron', 'pandemic-related', 'governance', 'keeps', 'rejects', 'judge,', 'degree', 'homicide', 'tougher', 'glaciers', 'shrinking', 'statements', 'laying', 'deal.', 'security,', 'commitments', 'gains', 'camera', 'plus', 'midwest', 'three-year-old', 'use,', 'harry', 'duchess', 'eye', 'stayed', 'buildings,', 'Read', 'more:', 'kenosha,', 'overseeing', 'forward.', 'seemingly', 'temporary', 'portland,', 'pro-Trump', 'page', 'managers', 'voices', '36', \"france's\", 'mysterious', 'collective', 'km', 'struck', 'personnel', 'calm', 'wildfires.', 'recession', 'chadwick', 'identity', 'renowned', 'italy,', 'common', 'screened', 'happy', 'touched', 'berlin', 'far-right', 'attract', 'lockdown,', 'slice', 'piece', 'blake', 'jail', 'weaker', 'term.', 'backdrop', 'outrage', 'covid-19', 'blasio', \"america's\", '@CNNOpinion', 'co-founder', '#SilenceIsNotAnOption', 'podcast:', 'covid-19,', 'homeland', 'resign', 'banning', 'investing', 'controlled', 'rep.', 'alaska', 'president-elect.', 'johns', 'hopkins', 'closely', 'texas,', 'grim', 'counties', 'arizona', 'project.', 'state’s', 'stood', '127,000', 'charts', 'US.', 'truth', 'this,', '@donlemon', 'approximately', '300,000', 'tweets', 'potentially', 'covid-19.', 'chicago', 'stay-at-home', 'roman', '12%', 'course', 'On', 'cuomo', 'thoughts', '🎧', 'listen:', 'recovery,', 'past,', 'reserve', 'notable', 'recognize', 'president-elect,', 'GOP', 'pentagon', 'alarmed', 'defense', 'inauguration', '--', 'justice,', 'dakota,', 'today’s', '@DrSanjayGupta', 'overwhelmed', 'McConnell', 'reject', 'montana', 'threatens', 'relying', 'pets', 'elderly', 'adults', 'difficulty', 'census', 'adviser', 'campaign,', 'indication', 'acknowledge', 'coordination', 'baseless', 'iPhone', 'mini', 'affirmative', 'us,', 'episodes', 'ET/PT', 'passing', '2024', 'so,', 'biden’s', 'decline', 'confronts', 'suggesting', 'divisive', 'fueled', 'peacekeeping', 'americans,', 'refuse', 'victory,', 'mocked', 'unveils', 'theme', 'guests', '📩', 'inbox', 'daily:', 'today:', 'evacuated', 'philippines', 'UK', 'covid,', 'brexit', '@lukemcgee', 'visual', 'overturn', 'win,', 'wild', 'talking', '@StCollinson', 'architecture', 'tennessee', 'sworn', 'primary', 'shanghai', 'entirety', 'relocated', 'dubbed', '\"walking', 'machine.\"', 'virus,', 'verge', '\"A', 'protests,', '@jgriffiths', 'you,', 'cites', '70%', '2008,', 'W.', 'collapse', 'hurricanes', 'exposing', 'robots', 'loved', 'ones.', 'board.', 'traveled', 'unlikely', 'ranked', 'CNN’s', 'labor', 'bernie', '“If', 'portfolio', 'brad', 'raffensperger', 'discusses', '“We', 'statewide', 'confirm', 'Covid-19.', 'lost.', 'champion', 'brave', '86.', '\"President', 'plain', 'placing', '@CillizzaCNN', 'el', 'paso', 'culture', 'results,', '20,', 'check:', 'police,', 'baselessly', 'university,', 'utah', 'nice', 'honor', 'india,', 'JUST', 'IN:', 'incoming', 'loeffler', 'perdue', '\"They', 'neighboring', 'traffic', 'moderna', 'navajo', 'all,', 'FDA', 'manufacturers', 'requirement', 'surrogate', 'wealth', 'sputnik', 'V', '92%', 'recognizing', 'lethal', 'McCain', 'cindy', 'regime', \"CNN's\", 'writes.', '1st', 'sydney', 'illinois,', 'position,', 'academy', 'nationally', 'grown', '@ForecasterEnten', 'revenge', 'morning,', 'slightly', 'mph', 'first:', 'spokeswoman', 'intent', 'arab', 'warren', 'We', 'victory.', 'authorized', 'drugmaker', 'BioNTech', 'ceremony', 'alongside', 'event.', 'confederate', 'traveling', 'zoo', 'england,', 'panda', 'VP', 'PROJECTION:', '#CNNElection', 'prevented', 'context', 'podcast.', 'rampant', 'devastating', 'dominated', 'women,', 'margaret', 'mexico,', 'flash', 'kong,', 'stripped', 'beijing', 'powers', 'mink', 'farms', 'associates', 'stacey', 'abrams', 'historically', 'graduates', 'producing', 'arts', 'baker', 'larry', 'maryland', \"month's\", 'norwegian', 'featuring', 'hall,', 'discover', 'dig', 'check', 'whip', 'ugly', 'protections', 'correspondents', 'photos', 'seriously', 'election:', 'jill', '60,000', 'closest', 'congratulate', 'la', 'adopted', 'cope', 'fauci,', 'allergy', 'diseases,', \"apple's\", '\"One', 'chip', 'pro', 'cusp', 'grounded', 'misinformation', 'cal', 'cunningham', 'thom', 'tillis', 'dramatically', \"democrats'\", 'eventually', 'endorsing', 'trump,\"', 'allies,', 'surprise', 'globally', 'reacts', 'paso,', 'pair', 'recep', 'tayyip', 'erdogan', 'congratulated', 'updates:', 'magnetic', 'posing', 'packing', 'unemployed', 'capture', 'runoff', 'bacteria', 'performed', '\"Jeopardy!\"', 'way,', '“I', 'can’t', 'citizens', 'mitch', 'chuck', 'schumer', 'chamber', 'behavior', 'republican,', 'Biden-Harris', \"team's\", 'jr.', 'committee,', 'question:', 'illinois', 'florida,', 'grief', 'via', 'broadcast', \"denmark's\", 'invalidate', 'prepares', 'administration.', '\"What', 'next,', 'dana', 'norway', 'waves', 'self-driving', 'II', 'theodore', 'McCarrick', 'archbishop', 'unfairly', 'carrier', 'apparel', 'transform', '(and', 'psychiatric', 'astronauts', 'iconic', 'photographs', 'prosecutor', 'examine', 'irregularities', 'far.', 'UAE', 'pressing', 'saeb', 'erekat', 'regulator', 'adverse', 'striking', 'gay', 'trusted', 'nervous', 'discoveries', 'egypt', 'tradition', 'exile', 'trebek,', 'pictures:', '90%', 'effective,', 'polarized', '@CNNOpinion.', 'urban', 'carson', 'summit', 'atlanta,', 'recreational', 'marijuana', 'qilian', 'disappearing', 'unpredictable', 'shortages,', 'resigns', 'When', 'watched', 'notre', 'dame', 'no.', \"harris'\", '50%', '\"no', 'confront', 'joseph', 'eli', 'emirates', 'sentences', 'assaulted', 'firing', 'christopher', 'miller,', 'center,', 'implement', \"McDonald's\", 'plant-based', \"campaign's\", '@JohnKingCNN', 'podcast', 'fastest', 'backs', 'jon', 'ossoff,', 'books', 'it,\"', 'congress.', '“It', '“What', 'effectiveness', 'esper,', 'pandemic’s', 'incumbent', 'split', 'sewage', 'explores', 'document', 'surged', 'covid', 'jared', 'k-pop', 'MTV', 'base', 'investigative', 'collins', 'latino', 'differences', 'latinos', \"zealand's\", 'borders', 'keys', 'life-threatening', 'defeat', 'heal', 'america?', 'beloved', 'devoted', '\"You', 'color', 'harris’', 'alpha', 'democrat,', 'one,', 'enten', 'landscape', 'normalcy', '...', 'unity', 'kushner', 'speeches', 'biden:', 'unify', 'favorite', 'fan', 'best,', '\"For', 'message.', 'office,', '\"When', 'soul', 'hometown', 'wilmington,', 'Watch', 'Follow', 'harris,', 'congratulating', '“We’re', 'enjoy', 'obamacare', '“This', 'female,', 'career.', 'defined', 'lie', 'tweeted', 'reads', 'did”', 'transition.', '“You', 'delaware,', '“It’s', 'states’', 'nation’s', '46th', 'torrential', 'clinch', 'spread,', 'meadows,', 'provisional', 'dedicated', 'helps', 'decide', 'meadows', 'damaged', 'know.', 'disperse', 'trajectory', 'suggests.', 'false.', 'watchers', 'counted,', 'zero', 'madison', 'records.', 'congressional', 'district.', 'unwilling', 'detail', 'sarah', 'identifies', 'transgender', 'prompt', 'recounts', 'explains', 'freedom', 'deadlines', 'correct', 'ballot,', 'defeats', 'martha', 'votes,', 'christie', 'edge', 'stands', 'all-important', 'hasn’t', '▪︎', 'nevada', 'carolina', 'beating', 'guatemala', 'honduras', 'alabama', 'constitution.', 'producer', 'cull', 'mutated', 'approve', \"alzheimer's\", 'focusing', 'cori', 'bush,', 'here.', 'missouri', 'rumors', 'photographers', 'expectations', 'seats.', 'far,', 'breaking', 'evidence,', 'rhode', '“The', 'scrutiny', 'sullivan', 'USPS', 'postmarked', 'count,', 'color.', 'what’s', 'topic', 'shaping', 'unemployment', 'coast.', 'fort', 'department.', 'jump', 'twitter,', 'YouTube', 'unpopular', 'oklahoma', 'nowhere', 'exit', 'warnings', 'reelection', 'election-related', 'symptoms.', 'podcast,', 'wall\"', 'labeled', 'legalize', 'jersey,', 'susan', 'setback', 'dakota', 'gig', 'lyft', 'delaware', 'await', 'updates.', '#CNNelection', 'absentee', 'well,', 'totally', 'abortion', 'undecided', 'House.', 'hawaii', 'abortion,', 'nebraska,', 'squad', 'alexandria', 'Ocasio-Cortez', 'minnesota,', 'iowa', 'joni', 'idaho', 'flag', 'colorado', 'proposition', 'lindsey', 'jaime', 'hampshire', 'hickenlooper', 'connecticut', 'marjorie', 'greene,', 'flew', 'vermont', 'LGBTQ', 'houston', 'wait.', 'wing', 'performance', 'cybersecurity', 'temple', 'other,', 'here!', 'quarterback', 'denver', 'washington.', 'winning.', 'they’re', 'tense', 'jewish', 'america,', 'deborah', 'alarming', 'voting?', 'disinformation?', 'fact,', 'apparently', 'officer,', 'pregnant', 'shortly', 'lives,', 'end?', 'continent', \"night's\", 'austrian', 'chancellor', 'man,', 'interactive', 'futures', 'sweeps', 'energy,', 'markets,', '-', 'america’s', 'economy?', 'again,', 'condemned', 'describing', 'weaken', 'tycoon', 'ant', 'ma', 'questioning', 'vienna,', 'austria’s', 'tuesday.', 'voting,', 'slave', 'neck', 'park,', 'approaches', 'spikes', 'materials', 'models,', 'wrap', 'chains', 'boarding', 'unrest', 'diverse', 'surprised', 'backlash', 'monarchy', '\"But', 'civic', 'profound', 'makers', 'african', 'chapter', 'electors', 'districts', 'favor', 'eta,', 'intensified', 'assailant', 'emerging', 'Day.', 'horrific', 'Asian-American', 'churches', 'sentenced', 'DOJ', 'apparent', 'questioned', 'players', 'dating', 'candidates,', 'solo', 'carolina.', 'echoes', '@JohnAvlon', 'immigrant', 'consistently', 'warm', 'rallies', 'feet', 'opinion', 'integrity.', 'focused', 'vs.', 'forgot', 'anger,', 'breath', 'podcasts', 'surge,', 'catastrophic', 'coronavirus:', 'vs', 'celebrated', 'atlanta', 'citizenship', 'race?', 'texas.', 'systems', 'wolf', \"university's\", 'cheer', 'palace', 'flagship', 'pledging', 'families.', 'many,', \"saturn's\", 'thick', 'molecule', 'measuring', 'sail', 'muslims', 'terrorist', \"africa's\", 'lightning', 'sounds', 'bats', 'naturally', 'situations', 'orthodox', 'priest', 'walmart', 'little-known', 'automaker', 'snatched', 'walter', 'wallace', 'pepper', 'spray', 'trafficking', 'force,', '@MaeveReston', '1918', 'worst,', 'flu.', 'scientific', 'realized', 'tall', 'relationship,', 'alliance,', 'approaches,', 'seize', 'US-Mexico', 'wall,', 'digestive', 'feces.', 'Cities', 'hornets\"', 'captured', 'kate', 'rubins', 'clinton', '538', 'interview.', '26%', 'hunting', 'run,', 'ventilation', '99%', 'viruses,', 'harvard', 'accepting', 'lebanese', 'inspiring', 'travelers', 'arrival', 'gloves', 'connery', 'beverages', 'heart', 'kind,', 'other.', 'spy', '90,', 'structures', 'utility', 'origin', 'reportedly', 'administration,', 'memory', 'clark', 'black,', 'nancy', 'sue', '\"My', 'album', 'boss', '$150', 'ohio,', 'burmese', 'python', 'Friday.', 'highway', 'nationwide,', 'proposals', 'marijuana.', 'history?', 'fracking', 'BBC', 'monetary', 'orleans', 'acquired', 'equity', 'owns', 'house?', 'pete', 'buttigieg', 'prior', 'praised', 'fragile', 'enter', '“He', 'shape', 'donors', 'stepped', 'danger', 'photographer', \"november's\", 'jinping', 'golden', 'jeffrey', 'epstein', 'hackers', 'trail.', 'scheme', \"florida's\", 'percentage', 'competitive', 'belgian', 'racing', 'team,', 'right,', 'tulsa', 'massacre', '1921', 'pivotal', 'iowa,', 'footage', 'fatal', 'place,', 'brett', 'so.', 'joins', 'march,', \"italy's\", 'hoped', 'pre-election', 'struggles', 'handing', 'milky', 'shutdown', 'facebook.', 'would-be', 'attends', 'czech', 'demographics', 'gridlock', 'significantly', 'minks', 'unexpected', 'euros', 'surpassing', 'ballot.', 'drive-through', 'expression', 'zealanders', 'xinjiang,', 'In', 'move,', '$4', '9/11', 'lasting', 'draft', 'assertion', '20%', 'colombia', 'transmit', 'norms', 'tenure', 'answer', 'pardon', 'richard', 'speaker', 'pelosi', 'terrorism', 'consequential', 'lawrence', 'substantive', 'If', 'adds.', 'pres.', 'rushed', 'response.', '17%', '30%', 'succeeded', 'battlegrounds', 'opposite', 'horror', 'crack', 'adidas', 'auction,', 'her,', 'necessarily', 'near-Earth', 'ossoff', 'unusually', 'fit', 'choosing', 'speaks', \"amazon's\", 'profit', 'soared', 'billion,', 'third-quarter', '14%', 'highlighting', 'obstacles', 'jr.,', 'scandal', 'modest', 'consensus', 'contentious', 'facebook,', 'core', 'exists', 'versus', 'stabbing', '\"very', '\"in', 'perhaps', '“not', 'fact-checking', 'aren’t', 'buying', \"you've\", 'stunning', 'hispanic', 'examines', 'models', 'Here’s', 'displaced', 'outlines', 'theater', 'stages', 'lilly', 'first-time', '40,000', 'second-quarter', 'google,', 'republic', 'bet', 'decapitated', 'samsung', 'profits', 'smartphone', '1950s', 'indians', 'diaspora', 'shoot', 'confronted', 'he’s', '“In', 'we’re', 'flat', 'conclude', 'compare', 'couples', 'confusion,', 'dodgers', 'kavanaugh', 'mistakenly', 'aircraft', 'jet', 'monument', 'substantial', 'ET,', 'club', \"europe's\", 'partial', 'CIA', 'disney', 'layoffs', '\"not', 'macron', 'announced,', 'frequently', 'successor', '27-year-old', 'disputes', 'plead', 'tomorrow', 'upper', 'canceled', 'woo', 'cultural', 'colonial', 'hands.', '19-year-old', 'endorsement', 'war,', 'mistakes', 'all-new', '#FirstLadies,', 'soccer', 'sparking', 'worries', 'renewed', 'replaces', 'turnout.', 'sacha', 'cohen', 'indoors', 'whoever', 'denial', 'baseball', 'unlike', 'tampa', 'rays', 'firefighters', '48', '165', 'daunting', 'qatar', 'abandoned', 'sprint', 'failures', 'younger', 'declares', 'point,', 'i’m', 'folks', 'reaction', 'classic', 'likes', 'apologized', 'stealing', 'violence,', 'loyalty', 'up,', 'Washington', 'don’t', 'pandemic:', 'audience', 'Biden.', 'latin', 'posed', 'he’ll', 'about?', 'solid', 'moon.', 'roosevelt', 'listing', 'acted', 'blocks', 'highs', 'comply', 'emily', 'predict', 'rebound', 'chronic', 'sufficient', 'full-on', '@ddale8', 'magazine', 'columnist', 'These', 'mate,', 'white,', 'dominant', 'firmly', 'uyghurs', 'motivation', 'justify', 'shield', 'approaching', 'republicans.', 'expected,', 'vietnam', 'evacuate', 'pew', 'mandate.', 'cycle', 'confirms', 'litigation', 'desire', 'firms,', 'clashes', 'riding', 'stance', 'article', 'we’ve', 'officials,', 'peak', '22.', '100%', 'paper', 'recycled', 'interference', 'torn', 'beaten', 'midwest,', 'age,', 'hungary', 'saving', 'republicans,', 'stakes', 'noise', 'boycott', 'cartoons', 'prophet', 'bennu', '14-year-old', '$25,000', 'Anika', \"chebrolu's\", 'invention', 'in-silico', 'methodology', 'selectively', 'bind', 'protein', 'SARS-CoV-2', 'pence’s', 'harrison,', 'challenger,', 'zoom', 'last-ditch', 'melbourne,', 'communist', 'capitalize', 'policy.', 'electronics', 'talent', 'located', 'insufficient', 'render', 'ineffective,', 'specialist', \"mexico's\", 'peru,', 'deploy', 'phrase', 'lesley', 'eleanor', 'elevate', 'instead,', 'Florida', 'portuguese', '“There', 'plagued', 'lifetime', 'wilton', 'gregory', 'African-American', 'appoint', '130,000', 'avoided', 'interventions', 'shirts', 'worker,', 'diet', 'tea', 'pressure,', 'bigger', 'boost,', 'side,', \"UK's\", 'sarcophagi', 'trove', 'ancient', 'X', 'breast', 'women.', '4.', 'randi', 'kaye', 'founded', 'ghost', 'pizza', 'taunted', 'disasters', 'anger', 'luck', 'frozen', 'reliance', 'shy', 'reeling', 'cool', 'near-total', 'year’s', 'justice’s', 'racially', 'francisco', 'adviser,', 'incredibly', 'democracy,', 'nobody', 'anniversary', 'stadium', 'it,”', 'game,', '“They', 'it.”', 'rule', 'standards', '“A', 'maya', 'civility', 'argument', 'McConnell,', 'confirming', 'editors', 'enters', 'With', 'sudan', 'normalize', 'plotting', 'predominantly', '60%', 'pushed', 'witness', 'writer', 'public,', '#Debates2020', 'claims,', 'topics', 'times,', \"thursday's\", 'men,', 'heightened', 'elsewhere', 'colorado,', 'Trump-Biden', '“Trump', 'debate?', 'clashed', 'Democratic', 'An', 'smart', 'probation', 'data,', 'happened.', 'lied', 'responds', 'typical', \"he'd\", '46', 'maine,', 'trails', 'pressured', 'handled', 'sight', 'text', 'customs', 'undocumented', 'lowest', 'won’t', 'infection,', 'declaring', 'foundation', 'improvement', \"sotheby's\", 'urges', 'Coca-Cola', 'participants', 'searching', 'bipartisan', 'ghislaine', 'deposition', 'machines', 'toppled', 'buhari', 'lagos', 'bloody', 'official,', 'bangkok', 'worrying', 'maker', '$8', 'power,', 'result,', 'strategic', 'rallying', 'favors', 'transformed', 'illustrated', 'pitching', 'scattershot', 'vastly', 'quarterly', 'democrats,', '2012', 'arguing', 'insult', \"AstraZeneca's\", 'brazilian', 'products.', 'Covid-19', 'lockdown.', 'women’s', 'trending', 'netherlands', 'dominate', 'me,', 'speech,', 'god', 'abruptly', 'CBS', \"utah's\", 'zion', 'suburbs', 'isn’t', 'exploded', 'epsilon', 'collect', 'floods', 'referred', '6%', 'paint', 'pursue', 'worsened', 'meat', 'pledges', 'openly', 'louis', 'pronounced', 'pursued', 'boxes', 'harnessing', 'motors', 'agents', 'buck', 'order,', 'assad', 'factory', 'explained', 'juror', 'closes', 'kansas', 'lay', 'person?', 'grapples', 'mistrust', 'kim', 'plants', 'intel', 'ocean,', 'strengthen', 'woes', 'trumpism', 'settle', 'chat', 'sand', 'sealed', \"sudan's\", 'barred', 'roots', 'service,', 'attacking', 'flee', 'suburbs.', 'hike', 'visa', 'periods', 'Thursday.', 'tries', 'except', 'attorneys', 'seekers', 'repeated', 'caricatures', 'muhammad', 'syrian', 'vowed', 'More', 'alibaba', 'grandmother', 'sport.', 'reagan', 'See', 'guide', 'mexican', 'involvement', \"kenya's\", 'all.', 'fun', 'blazes', 'averaging', 'sunday’s', 'soviet', 'remarkable', 'discussion', 'dan', 'interviews', 'QAnon,', 'machu', 'smaller,', 'next-generation', 'artwork', 'likelihood', 'songs', 'electricity', 'capturing', 'canal', 'tallies', 'live,', 'impeachment', 'scorched', 'europe.', 'year:', 'nick', 'saban', 'case,', 'virginia,', 'she’s', '“will', 'be,', '44', 'captain', 'installed', 'heated', 'denounce', 'president’s', '“To', 'giuliani,', 'ordinary', 'owe', 'distribute', 'tracked', 'collision', '10%', 'describes', 'films', '85%', 'dueling', 'ABC', 'outspoken', 'ronald', 'invest', 'weren’t', 'underscores', 'grip', 'complicated', 'biden?', 'furniture', 'diagnosis,', 'elected,', 'promoting', 'did,', 'sow', 'luxury', 'poverty', 'plays', 'salvador', \"'I\", 'destructive', 'discussed', '“a', 'satellite', 'you’re', 'sends', 'wins,', 'insider', 'editor,', 'decree', 'wall.', 'economist', 'gratitude', 'carter', 'halts', '“I’m', 'lesbian', 'protesters.', 'nears', 'singapore', 'pursuing', 'IPO', 'risky', 'gaming', 'industry,', 'discrimination', '“Our', 'them.”', 'barrett’s', 'mary', 'disturbing', 'angela', 'picks', 'takeaways', 'hearings.', '“no', 'exclusive:', 'venture', 'cluster', 'policies.', 'hours-long', 'lines.', 'vajiralongkorn', 'Listen', 'computer', 'works.', 'rights,', 'motivated', 'wonder', 'resurgent', 'roam', 'reflecting', 'there’s', 'convinced', 'still,', 'trillion', 'johnson,', 'afraid', 'kremlin', 'amnesty', 'publishing', 'pastor', 'deployed', 'destroy', 'cubs', 'news:', 'flipped', 'turkmenistan', 'gilded', 'inmates', 'county:', 'rises', 'surges.', 'weakening', 'steering', 'que', 'un', 'del', 'presidente', 'nude', 'talked', 'zimbabwe', 'percent', 'masters', 'augusta', 'ray', 'daily.', 'rahm', 'australia,', 'kong’s', 'masse', 'china’s', 'booming', 'protesting', 'hundred', 'prompting', 'vow', 'majority.', 'FTI', 'tabs', 'scenes', 'holocaust', 'yorker', 'hours,', 'bridge', 'cracking', 'world’s', 'radar', 'clues', 'Opinion', 'President', 'sells', 'silent', 'slowly', 'threw', 'willingness', 'smooth', 'georgia’s', 'recount.', 'encouraged', 'shocked', 'peru’s', 'unexpectedly', 'husband-and-wife', 'armistice', 'senate?', 'myanmar’s', 'aung', 'suu', 'signaled', 'ousted', 'populist', 'fed', 'austria', 'morrison', 'departure', 'harris’s', 'subway', 'supplier', 'paths', 'lael', 'party’s', 'defeat,', 'dark.', 'como', 'una', 'y', 'para', 'errors', 'crowded', 'mobility', 'maricopa', 'latest:', 'swung', 'disgraced', 'cardinal', 'report.', 'entertainment', 'theaters', 'retain', 'unsubstantiated', 'gore', 'reacted', '“When', 'cat', 'scheme,', 'why?', 'europe’s', 'nikol', 'ally', 'referendum', 'enduring', 'pegatron', 'releases', 'defeated', 'weakness', 'week:', 'democrats’', 'vaccine:', 'innovative', 'pfizer’s', 'declining', 'france’s', 'row', 'dangerously', 'trio', 'democrats.', 'irish', 'streetwear', '$2.1', 'VF', 'stigma', 'emerge', 'representatives.', 'australia’s', 'pound', 'estimates,', '7%', 'habitable', 'whatever', 'myanmar', 'kyi', '“With', 'denmark', 'bottom', 'racism.', 'ancestral', 'prayed', 'hindu', 'supporter', 'asks', 'merkel', 'heart,', 'live:', 'define', 'potent', 'has,', 'pittsburgh,', 'do,', 'wasn’t', 'early,', 'you’d', 'steal', 'changed.', 'trump:', 'decisive', 'urgency', 'mood', 'relative', 'Many', 'candidate,', 'quit', 'rewrite', 'Biden', 'tie', 'falsehoods', '#Election2020.', 'cure', '#Election2020', 'plumbing', 'clip', 'partisan', 'mammoth', 'midwestern', 'reckoning', 'populated', 'Miami-Dade', 'points.', 're-election,', 'correction:', \"facebook's\", '150', 'carl', 'bail', 'companies’', 'college,', 'shutter', 'people’s', 'noon', 'Eastern', 'pennsylvania’s', '#Election2020,', 'russia’s', 'rides', 'independence', 'gap', '200,000', 'demographic', 'rupert', 'reflect', 'shock', 'mexico’s', 'drastic', 'jair', 'bolsonaro', 'brazil,', 'laundering', 'relatively', 'Latest', 'recalibrate', 'tweet.', 'india’s', 'oregon,', 'angered', 'mothers', 'montana,', 'louisiana,', 'embraced', 'results?', '#ElectionDay', 'newsletter', 'carlos', '#ElectionDay.', '#election2020', 'tune', 'example', 'editor', 'republican.', 'mail,', 'headquarters', 'palm', 'origins', 'significance', 'administration’s', 'indonesia', 'africa', 'implementing', 'reflects', 'year?', 'quiz', 'writes,', 'california’s', 'trucks', 'achieve', 'genius', '‘The', 'foray', 'sculpture', 'hunger', 'corona', 'kills', 'coup', 'hacked', '1990s', '“Across', 'tale', 'beans', 'elections:', 'D.C.,', 'feels', 'high-profile', 'accuses', 'lights', 'dressed', 'wins.', 'Times/Siena', 'visitor', '“My', '“long', 'lingering', 'buoyed', 'cotton', 'kicked', 'aliens', 'doubles', 'boosting', 'pave', 'rallies,', 'introduction', 'bond.', 'bolivia', 'suspension', 'state-by-state', 'ballot?', 'working-class', 'zealand’s', 'furlough', 'forecasting', 'five-year', 'endorse', 'canary', 'rats', 'azerbaijan,', 'relationships', '🗳', 'merchandise', 'mississippi,', 'notably', 'smashed', 'jeremy', 'islamist', 'terrorism.', 'thursday’s', 'satire', 'neighborhoods', 'casualties', 'radical', 'imposes', 'outright', 'democracy.', 'Take', 'fridge', '👇', 'protests:', 'tower', 'euphoria', 'killings', 'beheading', '80%', 'cheap,', 'made.', 'japan’s', 'evidence.', 'embrace', 'college-educated', 'regularly', 'tutoring', 'kabul,', 'bullet', 'correspondent', '$250', 'reversed', 'korea’s', 'millennial', 'boredom', 'elephant', 'kristen', 'dollar', 'belgium', 'fact-checked', 'moscow', 'Find', 'moderator', 'sparring', 'tonight’s', '📌', 'tehran', 'figures,', 'april,', 'undergoing', 'goldman', 'malaysian', 'hears', 'achieved', 'militant', 'trains', 'corrupt', 'africa’s', 'shed', 'athletes', 'voters:', 'infect', '\"we', 'rhea', 'outlast', 'policymakers', 'gunfire', 'monopoly', 'ireland', 'lebanon,', 'shadowy', 'carnival', 'vaccines,', 'vegan', 'psychological', '“People', 'peru', 'surges', 'museums', 'newspapers', 'go:', 'best-known', 'thailand’s', 'ultra-Orthodox', 'value', 'masked', 'malaysia', 'legions', 'waking', 'oppose', 'subscribe', 'matthew', 'community,', 'descent', 'bound', 'inflame', 'invented', 'proportion', 'poses', 'livelihoods', 'christmas', 'cyprus', 'unleashed', 'they’d', 'mistake.', '@1843mag', '@SoumayaKeynes', 'assesses', '“Money', 'talks”', 'decade,', '@AnneMcElvoy', 'asks”', '@gavi,', 'roll-out', 'nations?', '@tomstandage', '@GaviSeth', 'ahead”', '“Checks', 'balance”', '-@jonfasman', '-@gelliottmorris', '-@DSORennie', 'intelligence”', 'booze', '“Babbage”', 'rigorous', 'fair-minded', '@PedderSophie', 'cartoon', 'intelligence.', 'intelligence”:', 'sweden’s', 'cheese', 'philly', 'cheesesteak', 'martín', \"economist's\", 'default', 'heritage', 'organising', 'relationships?', 'zumping', 'quarantinderen:', 'slang', 'circulation\"', 'involve?', 'st', 'minorities', '“Babbage”,', 'dr', 'react', 'one-strike-and-you’re-out', 'universe', 'console', 'OpenRAN', \"kelly's\", 'all-Democratic', 'lewinsky', 'broke?', 'islam', 'bored,', 'conspiracist,', '1666,', 'self-isolated', 'plague.', 'goes...', 'sir', \"lebanon's\", 'pupils', 'trot', 'tap', 'front-runners', 'tequila,', 'archive', '@chowardchoward', 'poppy', '“Editor’s', 'picks”', 'economist,', 'aloud', 'consoles', 'forecasts', 'carr', 'punish', '1963,', 'safeguards', 'kyrgyzstan', 'curious', 'sistine', '@projectlincoln', '@NHJennifer', '@KnCukier', '@T_Wainwright', 'delhi', 'mumbai', 'breakthrough', 'camps.', 'talks”,', '@SimonLong55', '@S_Rabinovitch', 'galicia', 'anyway?', 'nigel', 'blogger', 'elimination', 'astonishing', 'carpentry,', 'fukuyama', 'mr', 'brit', 'american?', 'armenia,', '@DrMatthewSweet', 'amis', 'bollywood', 'intelligence”,', '“dark', 'deploys', 'editor-in-chief', 'losers', 'difficult,', 'supply-chain', '@nadasanders', 'ahead\"', 'esper', 'hub', 'lira', 'boring', 'creativity?', 'equal', '@schipperlena', '-When', 'vaccine?', '-What', 'overcome?', '-How', 'distribution?', 'rivals', '@jonfasman', 'aloud.', 'presidency?', 'flock', 'globalisation', 'bobi', 'bookmark', 'shrink', 'programme', 'tigray', 'ethiopia', 'black-and-yellow', 'fred', 'perry', 'polo', \"“It's\", 'America', 'sony', 'one-third', 'farage', 'social-media', 'philadelphia’s', '1793.', 'local,', 'economist’s', 'reckons', 'maori', 'garment', 'golfing', 'barbecue', 'dads', 'wraps', 'militiamen', 'chafing', 'ahmed', \"ethiopia's\", '“Who', 'again.”', 'perpetual', 'all?', 'ethiopian', '8%', 'impressionism', 'seven-year-olds', '\\'pointillism\\'\"', 'bode', 'treasuries', 'resilience', 'mapped', 'accelerate', 'submit', '“Democracies', 'partisan.', 'unique...But', 'tribalised.”', 'tanzania', 'acrimonious', 'partisanship', '@BoFrankln', 'balance”:', 'voted?', 'asset', 'grows,', 'haven', 'telecoms', 'boats', \"tanzania's\", 'characters', 'japan,', 'SoftBank', 'plots', 'ethiopia’s', 'restive', 'welcome', 'fake.', '\"Babbage\"', 'wandered', \"philadelphia's\", 'evolution', 'creates', 'repudiation', 'coverage,', 'rooms', '“working', 'hotel”', 'change?', '@stevenmazie', 'elites', '@AChilkoti', 'worst-hit', 'somalia,', 'furious', 'laptev', '\"Checks', 'balance\"', 'armenians', 'samuel', 'paty', 'turchin', 'discord', 'hostility', 'NHS’s', '100m', 'fewest', 'autumn', 'analysis,', 'neck-and-neck', '@ARobertsjourno', 'sweden', 'group’s', 'iraq', 'puri', 'JFK', '@AmbJohnBolton', 'recalls', 'anti-politics', 'world?', '-And', \"character...he's\", 'been—particularly', \"space—he's\", 'senate.”', '@alokjha:', '-@m_c_marshall', '-@arikkershenbaum', '-@AstroKatie', 'bahrain', '@alokjha', 'singapore’s', 'hawkers', 'caps', 'biographies', 'begin?', '@charlie_mccann', '@LReynoldsMITIPC', 'high-tech', 'model,', 'hammer', 'fuelling', \"EU's\", 'culture?', '-@seanspicer', '-@LilyMasonPHD', 'cloaked', '“Firms', 'unlearn', 'period.”', '@MIT’s', '@workofthefuture', 'tectonic', 'china:', 'rejections', 'gift', 'pharmacy', 'embattled', '1%', 'drawn-out', 'JPMorgan', 'traders', 'LGBT', 'smartphones', 'uyghur', 'investigated', 'berlin’s', 'intelligence”.', 'illegal,', 'unreported', 'fleets”', '@R_Shanbhogue', 'cite', 'roads', 'Nagorno-Karabakh:', 'anti-immigrant', 'Balance”:', '-Our', '-@SoumayaKeynes', '-Health', 'slavea', 'chankova', 'safeguard', '@BreneBrown', 'exceed', 'perception', 'forecast,', 'hiring!', 'bill:', 'expertise', 'linger', 'stable', 'aboriginal', '\"Lockdowns', 'brake', 'strategy\".', '@dgurdasani1,', 'memorandum,', 'bankers', '@DanwWang', 'gavekal', 'dragonomics', 'tech?', 'post-covid', 'quieter', 'transformation', 'barrington', '@econcallum', 'rival?', 'teaches', '“Xinomics”', 'asking,', 'supply?', 'cultivate', 'non', 'sources...which', 'unexpectedly?”', 'fear”.', '“deep', 'fear”', 'science”', 'insights', 'wire', 'home?', 'dixon,', 'IWG,', 'NextEra', 'oversight', 'alexis,', 'connect,', 'emphasis', 'salary', 'defends', '-Does', 'productive?', 'for?', 'structures?', 'crude', 'titans', 'fear,', 'f1’s', 'v', 'seoul', 'cairo', 'computing', 'secular', 'taiwanese', 'physicists', 'congo', 'vijay', 'vaitheeswaran', 'extinction', 'proposes', 'uyghurs,', 'trumponomics', '1:', 'rome', 'erodes', 'resolve', 'overseas', 'trump?', 'conflict,', 'sachs', 'video-game', 'post-production.”', '@danacowley', 'mandalorian', 'in-camera,', 'mohammad', 'pioneer', 'bans', 'developments', 'volkswagen', '⬇️', 'jailed', 'click', '➡️', '[Thread]', \"ghana's\", 'rawlings', 'dies', 'stall', 'karabakh', '#BBCYourQuestions', '#BBCRealityCheck', '#Election2020:', 'sparks', '🇺🇸', '#Americast', '@BBCSounds', 'Latest:', 'pleads', 'clash', 'President-Elect', '📷', 'downed', 'portugal', 'gaga', 'covid-19:', 'cannon', 'pushes', 'House', 'criticised', '@BBCJonSopel', '@awzurcher', 'hezbollah', 'burst', '#elections2020', 'apologises', '@BBCNorthAmerica', '👉', 'launches', 'conflict:', 'Meet', 'picchu', 'reopens', 'attack:', 'hebdo', 'nile', 'swimming', 'sues', 'pulls', 'sars', 'covid:', 'mali', 'dublin', 'argentina', 'prayers', 'africa:', 'polish', 'boosts', 'venezuela', 'kidnapped', 'curfews', \"'not\", 'dismisses', 'Get', 'beheaded', 'footballer', 'yemen', 'suspends', '58', 'brexit:', 'EU-UK', 'pride', 'tightens', 'freed', 'lion', 'stuff', 'rages', 'roof', 'conley', 'night-time', 'madrid', '#VPDebate', 'shelling', 'roundup', 'venezuelans', 'conley,', 'second-hand', 'gang', 'rescuers', 'taxi', 'fatalities', \"venezuela's\", 'bloomberg', 'AP', 'wire:', '@AP', '#APFactCheck', 'SIGN', 'UP:', 'peruvian', '#APracecall', 'PHOTO', 'GALLERY:', '@AP_Politics', 'indonesian', 'THREAD:', 'dems', 'explains:', 'explainers', '@AP:', '@AP’s', '#AmericaDisrupted', 'turkey’s', 'midwest.', 'clergy', \"AP's\", 'tesla,', 'slump', 'alibaba,', '1M', 'desks', 'cease-fire', 'AP.', 'sao', '@frontlinepbs', '@GlobalRepCentre', 'retirement', 'client', '@JulietLinderman', '@MendozaMartha', 'burns', 'acres.', 'deutsche', 'referees', '@Breakingviews:', '@reuterspictures:', 'muggles', 'tencent', 'breakingviews', 'capital:', 'euro', 'reuters', '2021-2027', '@mak_robyn', 'seller', 'autonomous', 'curbs', 'thaw', '@Reuters', '@stecklow', 'fades', '@Breakingviews', 'extravaganza', 'LIVE:', '@aimeedonnellan', '#AskReuters', '@reuterspictures', '$74', \"singles'\", 'factbox:', 'timeline:', 'noodle', 'reassure', 'corp', '$56', 'GRAPHIC', 'hole-in-one', 'lufthansa', 'pfizer,', 'firecrackers', 'insurer', '#ReutersLive', '@SadiqKhan', '@Heidi_LDN', '@dasha_reuters', 'view:', 'tally,', 'honda', 'MAX', 'vans', 'J.C.', '@ReutersGraphics', 'xbox', 'pandemic-driven', '@sudarsansand', 'PlayStation', 'WATCH:', 'IKEA', 'ICYMI:', 'dividers', 'kaliningrad', 'butcher,', \"rudy's,\", 'jodie', 'Turner-Smith', \"arabia's\", 'shafa', 'meat-free', 'columbus,', \"nevada's\", 'partygoers', 'RSA', 'full-size', '$GM', 'full-year', 'import']\n",
            "BEFORE filtering, there were 18632 tweets\n",
            "AFTER filtering, there are 10685 tweets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls0kt3-Nq-0X"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujL6TdR0q-DV",
        "outputId": "c42200c1-f732-48cb-9075-1d69535c1318",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Bidirectional, BatchNormalization, Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.data_utils import get_file\n",
        "import random\n",
        "import io\n",
        "from google.colab import files\n",
        "!pip3 install truecase\n",
        "import truecase\n",
        "\n",
        "INPUT_LENGTH = 5  # based on INPUT_LENGTH characters, our model generates the next character\n",
        "GENERATED_TWEET_LENGTH = 20 # words\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def get_truecase(sentence):\n",
        "    old_words = sentence.split(' ')\n",
        "    new_words = truecase.get_true_case(sentence).split(' ')\n",
        "    print('raw truecase:', ' '.join(new_words))\n",
        "    for old_word in old_words:\n",
        "        if not is_normal_capitalization(old_word):\n",
        "            var1 = old_word.lower()\n",
        "            var2 = var1[0].upper() + var1[1:]\n",
        "            if var1 in new_words:\n",
        "                new_words[new_words.index(var1)] = old_word\n",
        "            elif var2 in new_words:\n",
        "                new_words[new_words.index(var2)] = old_word\n",
        "    return ' '.join(new_words)\n",
        "    # return ' '.join([new_words[i] if is_normal_capitalization(old_words[i]) else old_words[i] for i in range(len(old_words))])\n",
        "\n",
        "def on_epoch_end(epoch, _, data, model):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    for _ in range(2):     # use 10 different tweets as samples\n",
        "        tweet = np.random.choice(data) # select random tweet\n",
        "        start_index = 0\n",
        "\n",
        "        for diversity in [0.2, 0.4, 0.6, 1.0]:\n",
        "        # for diversity in [0.1, 0.2, 0.3, 0.4]:\n",
        "        # for diversity in [0.3, 0.4, 0.5]:\n",
        "            print('----- diversity:', diversity)\n",
        "\n",
        "            generated = ''\n",
        "            sentence = tweet.split(' ')[start_index: start_index + INPUT_LENGTH]\n",
        "            generated += ' '.join(sentence)\n",
        "            print('----- Generating with seed: \"' + ' '.join(sentence) + '\"')\n",
        "            # sys.stdout.write(generated)\n",
        "\n",
        "            for i in range(GENERATED_TWEET_LENGTH):\n",
        "                x_pred = np.zeros((1, INPUT_LENGTH, len(words_list)))\n",
        "                for t, word in enumerate(sentence):\n",
        "                    x_pred[0, t, word_to_index[word]] = 1.\n",
        "\n",
        "                preds = model.predict(x_pred, verbose=0)[0]\n",
        "                next_index = sample(preds, diversity)\n",
        "                next_word = index_to_word[next_index]\n",
        "                generated += ' ' + next_word\n",
        "                sentence = sentence[1:] + [next_word]\n",
        "\n",
        "                # sys.stdout.write(next_word)\n",
        "                # sys.stdout.flush()\n",
        "            print(generated)\n",
        "            print('with truecase:')\n",
        "            # preserve\n",
        "            print(get_truecase(generated))\n",
        "            print()\n",
        "    # save and download the model\n",
        "    model.save('/content/model')\n",
        "    !zip -r /content/model.zip /content/model\n",
        "    files.download('/content/model.zip')\n",
        "\n",
        "\n",
        "def train_from_data(data, train_limit=None):\n",
        "    # convert the raw tweets list to input and output\n",
        "    # input is equal to INPUT_LENGTH characters, output is a single character\n",
        "    if train_limit:\n",
        "        data = data[:train_limit]\n",
        "    sentences = []\n",
        "    next_words = []\n",
        "    for tweet in data:\n",
        "        tweet_words = tweet.split(' ')\n",
        "        for i in range(0, len(tweet_words) - INPUT_LENGTH):\n",
        "            sentences.append(tweet_words[i: i + INPUT_LENGTH])\n",
        "            next_words.append(tweet_words[i + INPUT_LENGTH])\n",
        "    print('# training samples:', len(sentences))\n",
        "    # for i in range(10):\n",
        "    #     print(sentences[i],'->',next_words[i])\n",
        "\n",
        "    # vectorize the data\n",
        "    print('Vectorization...')\n",
        "    x = np.zeros((len(sentences), INPUT_LENGTH, len(words_list)), dtype=np.bool)\n",
        "    y = np.zeros((len(sentences), len(words_list)), dtype=np.bool)\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        for t, word in enumerate(sentence):\n",
        "            x[i, t, word_to_index[word]] = 1\n",
        "        y[i, word_to_index[next_words[i]]] = 1\n",
        "\n",
        "    # build the model\n",
        "    print('Build model...')\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(INPUT_LENGTH, len(words_list))))\n",
        "    # model.add(LSTM(len(VALID_CHARS) * 7, input_shape=(INPUT_LENGTH, len(VALID_CHARS))))\n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('selu'))\n",
        "\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('selu'))\n",
        "\n",
        "    # model.add(Dense(len(VALID_CHARS)*4))\n",
        "    # model.add(BatchNormalization())\n",
        "    # model.add(Activation('selu'))\n",
        "\n",
        "    # model.add(Bidirectional(LSTM(128), input_shape=(INPUT_LENGTH, len(VALID_CHARS))))\n",
        "    model.add(Dense(len(words_list), activation='softmax'))\n",
        "\n",
        "    # optimizer = RMSprop(lr=0.01)\n",
        "    optimizer = Adam()\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    epochs = 10\n",
        "    \n",
        "    print_callback = LambdaCallback(on_epoch_end=lambda a, b: on_epoch_end(a, b, data, model))\n",
        "\n",
        "    # train the model\n",
        "    model.fit(x, y,\n",
        "            epochs=epochs,\n",
        "            callbacks=[print_callback]\n",
        "            )\n",
        "\n",
        "    # save and download the model\n",
        "    model.save('/content/model')\n",
        "    !zip -r /content/model.zip /content/model\n",
        "    files.download('/content/model.zip')\n",
        "\n",
        "def main():\n",
        "    print(\"number of tweets:\", len(tweets))\n",
        "    train_from_data(tweets)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: truecase in /usr/local/lib/python3.6/dist-packages (0.0.11)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from truecase) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->truecase) (1.15.0)\n",
            "number of tweets: 8104\n",
            "# training samples: 106272\n",
            "Vectorization...\n",
            "Build model...\n",
            "Epoch 1/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 6.0539 - accuracy: 0.1283\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"thank you nevada! #AmericaFirst #MakeAmericaGreatAgain\"\n",
            "thank you nevada! #AmericaFirst #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain\n",
            "with truecase:\n",
            "raw truecase: Thank you Nevada! #Americafirst #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain\n",
            "Thank you Nevada! #Americafirst #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"thank you nevada! #AmericaFirst #MakeAmericaGreatAgain\"\n",
            "thank you nevada! #AmericaFirst #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday\n",
            "with truecase:\n",
            "raw truecase: Thank you Nevada! #Americafirst #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday\n",
            "Thank you Nevada! #Americafirst #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"thank you nevada! #AmericaFirst #MakeAmericaGreatAgain\"\n",
            "thank you nevada! #AmericaFirst #MakeAmericaGreatAgain #ImWithYou #MAGA Tickets: on the massive tonight! #MakeAmericaGreatAgain #Trump2016 #WIPrimary #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #WIPrimary #SuperTuesday #MakeAmericaGreatAgain\n",
            "with truecase:\n",
            "raw truecase: Thank you Nevada! #Americafirst #Makeamericagreatagain #Imwithyou #Maga tickets: on the massive tonight! #Makeamericagreatagain #Trump2016 #Wiprimary #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Wiprimary #Supertuesday #Makeamericagreatagain\n",
            "Thank you Nevada! #Americafirst #Makeamericagreatagain #Imwithyou #Maga tickets: on the massive tonight! #Makeamericagreatagain #Trump2016 #Wiprimary #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Wiprimary #Supertuesday #Makeamericagreatagain\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"thank you nevada! #AmericaFirst #MakeAmericaGreatAgain\"\n",
            "thank you nevada! #AmericaFirst #MakeAmericaGreatAgain #Trump2016 #WIPrimary @Patriots available to 2 hours on congratulations to it. my speech administration supporters with panels an bought on\n",
            "with truecase:\n",
            "raw truecase: Thank you Nevada! #Americafirst #Makeamericagreatagain #Trump2016 #Wiprimary @Patriots available to 2 hours on congratulations to it. My speech administration supporters with panels an bought on\n",
            "Thank you Nevada! #Americafirst #Makeamericagreatagain #Trump2016 #Wiprimary @Patriots available to 2 hours on congratulations to it. My speech administration supporters with panels an bought on\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"will be on @oreillyfactor tonight.\"\n",
            "will be on @oreillyfactor tonight. enjoy! #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016\n",
            "with truecase:\n",
            "raw truecase: Will be on @Oreillyfactor tonight. enjoy! #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016\n",
            "Will be on @Oreillyfactor tonight. enjoy! #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"will be on @oreillyfactor tonight.\"\n",
            "will be on @oreillyfactor tonight. enjoy! #Trump2016 #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #FITN #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain\n",
            "with truecase:\n",
            "raw truecase: Will be on @Oreillyfactor tonight. enjoy! #Trump2016 #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Fitn #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain\n",
            "Will be on @Oreillyfactor tonight. enjoy! #Trump2016 #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Fitn #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"will be on @oreillyfactor tonight.\"\n",
            "will be on @oreillyfactor tonight. thank you to you for my I am the best thing to not a to run campaign HQ at trump\n",
            "with truecase:\n",
            "raw truecase: Will be on @Oreillyfactor tonight. Thank you to you for my I am the best thing to not a to run campaign Hq at Trump\n",
            "Will be on @Oreillyfactor tonight. Thank you to you for my I am the best thing to not a to run campaign HQ at Trump\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"will be on @oreillyfactor tonight.\"\n",
            "will be on @oreillyfactor tonight. very she’s after the U.S. china is a badly but he look at nothing now. J. thank you! #SuperTuesday #MAGA\n",
            "with truecase:\n",
            "raw truecase: Will be on @Oreillyfactor tonight. very she ’ s after the U. S. China is a badly but he look at nothing now. J. Thank you! #Supertuesday #Maga\n",
            "Will be on @Oreillyfactor tonight. very she ’ s after the U. S. China is a badly but he look at nothing now. J. Thank you! #Supertuesday #Maga\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 89%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_520e8fe0-5943-48d0-a829-236e3ffed50f\", \"model.zip\", 38781821)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3321/3321 [==============================] - 381s 115ms/step - loss: 6.0539 - accuracy: 0.1283\n",
            "Epoch 2/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 4.8854 - accuracy: 0.1965\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"wise words from my in\"\n",
            "wise words from my in new york post office in D.C. on the world of the world class amenities in the world of the world\n",
            "with truecase:\n",
            "raw truecase: Wise words from my in New York post office in D. C. on the world of the world class amenities in the world of the world\n",
            "Wise words from my in New York post office in D. C. on the world of the world class amenities in the world of the world\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"wise words from my in\"\n",
            "wise words from my in new york poll is going to be great american flag &amp; they have a complete waste. total lie to the\n",
            "with truecase:\n",
            "raw truecase: Wise words from my in New York poll is going to be great American flag& they have a complete waste. Total lie to the\n",
            "Wise words from my in New York poll is going to be great American flag& they have a complete waste. Total lie to the\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"wise words from my in\"\n",
            "wise words from my in new york poll is he is an amazing evening! be on thursday night. now they have to be on the\n",
            "with truecase:\n",
            "raw truecase: Wise words from my in New York poll is he is an amazing evening! be on Thursday night. Now they have to be on the\n",
            "Wise words from my in New York poll is he is an amazing evening! be on Thursday night. Now they have to be on the\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"wise words from my in\"\n",
            "wise words from my in born in @RNC convention. will be a great missed! live able to run for focus on the media russia and\n",
            "with truecase:\n",
            "raw truecase: Wise words from my in born in @Rnc convention. will be a great missed! live able to run for focus on the media Russia and\n",
            "Wise words from my in born in @Rnc convention. will be a great missed! live able to run for focus on the media Russia and\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"how can any senator vote\"\n",
            "how can any senator vote for the republican convention center was a total failure of the U.S. is a total disaster. we have a great\n",
            "with truecase:\n",
            "raw truecase: How can any Senator vote for the Republican convention center was a total failure of the U. S. is a total disaster. We have a great\n",
            "How can any Senator vote for the Republican convention center was a total failure of the U. S. is a total disaster. We have a great\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"how can any senator vote\"\n",
            "how can any senator vote for the republican convention center was a great state of the state of the world. we need to get away\n",
            "with truecase:\n",
            "raw truecase: How can any Senator vote for the Republican convention center was a great state of the state of the world. We need to get away\n",
            "How can any Senator vote for the Republican convention center was a great state of the state of the world. We need to get away\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"how can any senator vote\"\n",
            "how can any senator vote in the republican convention center at the world convention center of the world is over. will be a great job\n",
            "with truecase:\n",
            "raw truecase: How can any Senator vote in the Republican convention center at the world convention center of the world is over. will be a great job\n",
            "How can any Senator vote in the Republican convention center at the world convention center of the world is over. will be a great job\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"how can any senator vote\"\n",
            "how can any senator vote for rubio and nation. obama this election premiere wasted on me, dress this rape will be like the A true\n",
            "with truecase:\n",
            "raw truecase: How can any Senator vote for Rubio and nation. Obama this election premiere wasted on me, dress this rape will be like the a true\n",
            "How can any Senator vote for Rubio and nation. Obama this election premiere wasted on me, dress this rape will be like the A true\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 89%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d7a63e54-ec73-430f-a097-ef5720a94276\", \"model.zip\", 38737467)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3321/3321 [==============================] - 359s 108ms/step - loss: 4.8854 - accuracy: 0.1965\n",
            "Epoch 3/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 4.1258 - accuracy: 0.2491\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"looking forward to returning to\"\n",
            "looking forward to returning to the state of the union speech was amazing - and a great time to get the great state of the\n",
            "with truecase:\n",
            "raw truecase: Looking forward to returning to the state of the Union speech was amazing- and a great time to get the great state of the\n",
            "Looking forward to returning to the state of the Union speech was amazing- and a great time to get the great state of the\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"looking forward to returning to\"\n",
            "looking forward to returning to the state of the union speech was amazing people. will be back in arizona and will be a disaster for\n",
            "with truecase:\n",
            "raw truecase: Looking forward to returning to the state of the Union speech was amazing people. will be back in Arizona and will be a disaster for\n",
            "Looking forward to returning to the state of the Union speech was amazing people. will be back in Arizona and will be a disaster for\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"looking forward to returning to\"\n",
            "looking forward to returning to the state of the state of south carolina. fantastic crowd and fantastic amazing people! now I will be to see\n",
            "with truecase:\n",
            "raw truecase: Looking forward to returning to the state of the state of South Carolina. fantastic crowd and fantastic amazing people! now I will be to see\n",
            "Looking forward to returning to the state of the state of South Carolina. fantastic crowd and fantastic amazing people! now I will be to see\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"looking forward to returning to\"\n",
            "looking forward to returning to arizona after the election. fantastic primary voters - look phone in under job, before our country, &amp; don't want the\n",
            "with truecase:\n",
            "raw truecase: Looking forward to returning to Arizona after the election. fantastic primary voters- look phone in under job, before our country,& don't want the\n",
            "Looking forward to returning to Arizona after the election. fantastic primary voters- look phone in under job, before our country,& don't want the\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"thank you #Trump2016 #MakeAmericaGreatAgain #TrumpTrain\"\n",
            "thank you #Trump2016 #MakeAmericaGreatAgain #TrumpTrain #Trump2016 #MakeAmericaGreatAgain Tickets: #Trump2016 Tickets: #FITN #NHPrimary A great honor! #MakeAmericaGreatAgain #Trump2016 #MakeAmericaGreatAgain #Trump2016 Tickets: #FITN #NHPrimary #Trump2016 #MakeAmericaGreatAgain #Trump2016\n",
            "with truecase:\n",
            "raw truecase: Thank you #Trump2016 #Makeamericagreatagain #Trumptrain #Trump2016 #Makeamericagreatagain tickets: #Trump2016 tickets: #Fitn #Nhprimary a great honor! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trump2016 tickets: #Fitn #Nhprimary #Trump2016 #Makeamericagreatagain #Trump2016\n",
            "Thank you #Trump2016 #Makeamericagreatagain #Trumptrain #Trump2016 #Makeamericagreatagain tickets: #Trump2016 tickets: #Fitn #Nhprimary A great honor! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trump2016 tickets: #Fitn #Nhprimary #Trump2016 #Makeamericagreatagain #Trump2016\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"thank you #Trump2016 #MakeAmericaGreatAgain #TrumpTrain\"\n",
            "thank you #Trump2016 #MakeAmericaGreatAgain #TrumpTrain #MakeAmericaGreatAgain #Trump2016 Tickets: #Trump2016 #MakeAmericaGreatAgain Tickets: #FITN #Trump2016 Tickets: #MakeAmericaGreatAgain #Trump2016 Tickets: #MakeAmericaGreatAgain #Trump2016 Tickets: #FITN #NHPrimary #Trump2016 #MakeAmericaGreatAgain #Trump2016\n",
            "with truecase:\n",
            "raw truecase: Thank you #Trump2016 #Makeamericagreatagain #Trumptrain #Makeamericagreatagain #Trump2016 tickets: #Trump2016 #Makeamericagreatagain tickets: #Fitn #Trump2016 tickets: #Makeamericagreatagain #Trump2016 tickets: #Makeamericagreatagain #Trump2016 tickets: #Fitn #Nhprimary #Trump2016 #Makeamericagreatagain #Trump2016\n",
            "Thank you #Trump2016 #Makeamericagreatagain #Trumptrain #Makeamericagreatagain #Trump2016 tickets: #Trump2016 #Makeamericagreatagain tickets: #Fitn #Trump2016 tickets: #Makeamericagreatagain #Trump2016 tickets: #Makeamericagreatagain #Trump2016 tickets: #Fitn #Nhprimary #Trump2016 #Makeamericagreatagain #Trump2016\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"thank you #Trump2016 #MakeAmericaGreatAgain #TrumpTrain\"\n",
            "thank you #Trump2016 #MakeAmericaGreatAgain #TrumpTrain #Trump2016 Tickets: #FITN #NHPrimary and will be a major event in ohio was a great event in tonight's debate? a\n",
            "with truecase:\n",
            "raw truecase: Thank you #Trump2016 #Makeamericagreatagain #Trumptrain #Trump2016 tickets: #Fitn #Nhprimary and will be a major event in Ohio was a great event in tonight's debate? a\n",
            "Thank you #Trump2016 #Makeamericagreatagain #Trumptrain #Trump2016 tickets: #Fitn #Nhprimary and will be a major event in Ohio was a great event in tonight's debate? a\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"thank you #Trump2016 #MakeAmericaGreatAgain #TrumpTrain\"\n",
            "thank you #Trump2016 #MakeAmericaGreatAgain #TrumpTrain #FITN #Trump2016 #MakeAmericaGreatAgain #Trump2016 Tickets: -- #ImWithYou Tickets: winston churchill at 9:00 A.M. on @FoxNews. enjoy! @FoxNews @TrumpDoral is an\n",
            "with truecase:\n",
            "raw truecase: Thank you #Trump2016 #Makeamericagreatagain #Trumptrain #Fitn #Trump2016 #Makeamericagreatagain #Trump2016 tickets:-- #Imwithyou tickets: Winston Churchill at 9:00 a. M. On @Foxnews. enjoy! @Foxnews @Trumpdoral is an\n",
            "Thank you #Trump2016 #Makeamericagreatagain #Trumptrain #Fitn #Trump2016 #Makeamericagreatagain #Trump2016 tickets:-- #Imwithyou tickets: Winston Churchill at 9:00 a. M. On @Foxnews. enjoy! @Foxnews @Trumpdoral is an\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 90%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3aa9bba0-9692-4adb-b186-31d32fcdea6e\", \"model.zip\", 38786618)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3321/3321 [==============================] - 349s 105ms/step - loss: 4.1258 - accuracy: 0.2491\n",
            "Epoch 4/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 3.4457 - accuracy: 0.3155\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"the trump organization purchase of\"\n",
            "the trump organization purchase of doral in miami. trump tower during the trump campaign has been a total disaster for the fact that I am\n",
            "with truecase:\n",
            "raw truecase: The Trump organization purchase of Doral in Miami. Trump tower during the Trump campaign has been a total disaster for the fact that I am\n",
            "The Trump organization purchase of Doral in Miami. Trump tower during the Trump campaign has been a total disaster for the fact that I am\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"the trump organization purchase of\"\n",
            "the trump organization purchase of doral in miami. I will be back soon! #Trump2016 #MakeAmericaGreatAgain #Trump2016 #FITN #Trump2016 #IACaucus #FITN #Trump2016 #MakeAmericaGreatAgain #FITN #Trump2016 #MakeAmericaGreatAgain\n",
            "with truecase:\n",
            "raw truecase: The Trump organization purchase of Doral in Miami. I will be back soon! #Trump2016 #Makeamericagreatagain #Trump2016 #Fitn #Trump2016 #Iacaucus #Fitn #Trump2016 #Makeamericagreatagain #Fitn #Trump2016 #Makeamericagreatagain\n",
            "The Trump organization purchase of Doral in Miami. I will be back soon! #Trump2016 #Makeamericagreatagain #Trump2016 #Fitn #Trump2016 #Iacaucus #Fitn #Trump2016 #Makeamericagreatagain #Fitn #Trump2016 #Makeamericagreatagain\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"the trump organization purchase of\"\n",
            "the trump organization purchase of doral in miami. thank you and very nice words. we will be back soon! #Trump2016 #MakeAmericaGreatAgain #Trump2016 #FITN #FITN #Trump2016\n",
            "with truecase:\n",
            "raw truecase: The Trump organization purchase of Doral in Miami. Thank you and very nice words. We will be back soon! #Trump2016 #Makeamericagreatagain #Trump2016 #Fitn #Fitn #Trump2016\n",
            "The Trump organization purchase of Doral in Miami. Thank you and very nice words. We will be back soon! #Trump2016 #Makeamericagreatagain #Trump2016 #Fitn #Fitn #Trump2016\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"the trump organization purchase of\"\n",
            "the trump organization purchase of filed standing 6 options for obama will be back in companies are with the big words where I look forward\n",
            "with truecase:\n",
            "raw truecase: The Trump organization purchase of filed standing 6 options for Obama will be back in companies are with the big words where I look forward\n",
            "The Trump organization purchase of filed standing 6 options for Obama will be back in companies are with the big words where I look forward\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"the building of the wall\"\n",
            "the building of the wall street poll is just released a total disaster. he has the gold makes the rules. I have a great job!\n",
            "with truecase:\n",
            "raw truecase: The building of the Wall Street poll is just released a total disaster. He has the gold makes the rules. I have a great job!\n",
            "The building of the Wall Street poll is just released a total disaster. He has the gold makes the rules. I have a great job!\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"the building of the wall\"\n",
            "the building of the wall street poll is a total disaster for the U.S., &amp; trump tower during the campaign is a total joke, a\n",
            "with truecase:\n",
            "raw truecase: The building of the Wall Street poll is a total disaster for the U. S.,& Trump tower during the campaign is a total joke, a\n",
            "The building of the Wall Street poll is a total disaster for the U. S.,& Trump tower during the campaign is a total joke, a\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"the building of the wall\"\n",
            "the building of the wall in new hampshire. will be the very soon! #Trump2016 #MakeAmericaGreatAgain #FITN #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #MakeAmericaGreatAgain #FITN #Trump2016 #IACaucus #FITN\n",
            "with truecase:\n",
            "raw truecase: The building of the wall in New Hampshire. will be the very soon! #Trump2016 #Makeamericagreatagain #Fitn #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Fitn #Trump2016 #Iacaucus #Fitn\n",
            "The building of the wall in New Hampshire. will be the very soon! #Trump2016 #Makeamericagreatagain #Fitn #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Fitn #Trump2016 #Iacaucus #Fitn\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"the building of the wall\"\n",
            "the building of the wall to get it. big interests. will now tomorrow. see such something happens at me in the trump tower of from\n",
            "with truecase:\n",
            "raw truecase: The building of the wall to get it. big interests. will now tomorrow. see such something happens at me in the Trump tower of from\n",
            "The building of the wall to get it. big interests. will now tomorrow. see such something happens at me in the Trump tower of from\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 90%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3e71defd-9b54-4d5e-ae44-b34eed19b064\", \"model.zip\", 38783688)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3321/3321 [==============================] - 365s 110ms/step - loss: 3.4457 - accuracy: 0.3155\n",
            "Epoch 5/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 2.8458 - accuracy: 0.3951\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"money should be at work\"\n",
            "money should be at work for a long time &amp; sadly, he gets nothing done. loser! @VanityFair are a way he is a third party\n",
            "with truecase:\n",
            "raw truecase: Money should be at work for a long time& sadly, he gets nothing done. loser! @Vanityfair are a way he is a third party\n",
            "Money should be at work for a long time& sadly, he gets nothing done. loser! @Vanityfair are a way he is a third party\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"money should be at work\"\n",
            "money should be at work is a big deal. -- the art of the deal about me! will be the finest in the U.S. history.\n",
            "with truecase:\n",
            "raw truecase: Money should be at work is a big deal.-- the art of the deal about me! will be the finest in the U. S. history.\n",
            "Money should be at work is a big deal.-- the art of the deal about me! will be the finest in the U. S. history.\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"money should be at work\"\n",
            "money should be at work done to be in U.S. history. great opportunity to keep what an takes &amp; stay family &amp; others pay for\n",
            "with truecase:\n",
            "raw truecase: Money should be at work done to be in U. S. history. great opportunity to keep what an takes& stay family& others pay for\n",
            "Money should be at work done to be in U. S. history. great opportunity to keep what an takes& stay family& others pay for\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"money should be at work\"\n",
            "money should be at work is big! they can die just never but bad, #AmericaFirst #ImWithYou #AmericaFirst #MAGA Tickets: Tickets: #MAGA Tickets: let you down.\n",
            "with truecase:\n",
            "raw truecase: Money should be at work is big! they can die just never but bad, #Americafirst #Imwithyou #Americafirst #Maga tickets: tickets: #Maga tickets: let you down.\n",
            "Money should be at work is big! they can die just never but bad, #Americafirst #Imwithyou #Americafirst #Maga tickets: tickets: #Maga tickets: let you down.\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"lightweight attorney general eric schneiderman\"\n",
            "lightweight attorney general eric schneiderman is a total winner! he understood - he did not leave a job which is a total disaster. we can\n",
            "with truecase:\n",
            "raw truecase: Lightweight Attorney General Eric Schneiderman is a total winner! he understood- he did not leave a job which is a total disaster. We can\n",
            "Lightweight Attorney General Eric Schneiderman is a total winner! he understood- he did not leave a job which is a total disaster. We can\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"lightweight attorney general eric schneiderman\"\n",
            "lightweight attorney general eric schneiderman is so so many that americans still thinks romney won. a race is a disaster, but we never had a\n",
            "with truecase:\n",
            "raw truecase: Lightweight Attorney General Eric Schneiderman is so so many that Americans still thinks Romney won. a race is a disaster, but we never had a\n",
            "Lightweight Attorney General Eric Schneiderman is so so many that Americans still thinks Romney won. a race is a disaster, but we never had a\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"lightweight attorney general eric schneiderman\"\n",
            "lightweight attorney general eric schneiderman is considered a total big real estate public golf course in scotland and the middle class to be paying for\n",
            "with truecase:\n",
            "raw truecase: Lightweight Attorney General Eric Schneiderman is considered a total big real estate public golf course in Scotland and the middle class to be paying for\n",
            "Lightweight Attorney General Eric Schneiderman is considered a total big real estate public golf course in Scotland and the middle class to be paying for\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"lightweight attorney general eric schneiderman\"\n",
            "lightweight attorney general eric schneiderman is exposed a featured with secretary of arizona. that both third party and very dishonest future to WORLD republican own\n",
            "with truecase:\n",
            "raw truecase: Lightweight Attorney General Eric Schneiderman is exposed a featured with Secretary of Arizona. that both third party and very dishonest future to world Republican own\n",
            "Lightweight Attorney General Eric Schneiderman is exposed a featured with Secretary of Arizona. that both third party and very dishonest future to WORLD Republican own\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 90%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_38d70ef1-28dc-4460-9753-cf9ae577fc72\", \"model.zip\", 38834631)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3321/3321 [==============================] - 379s 114ms/step - loss: 2.8458 - accuracy: 0.3951\n",
            "Epoch 6/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 2.3496 - accuracy: 0.4763\n",
            "----- Generating text after Epoch: 5\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"germany is going through massive\"\n",
            "germany is going through massive attacks to its people by the wrong almost at the debate? just can't make the deal with iran deal, especially\n",
            "with truecase:\n",
            "raw truecase: Germany is going through massive attacks to its people by the wrong almost at the debate? just can't make the deal with Iran deal, especially\n",
            "Germany is going through massive attacks to its people by the wrong almost at the debate? just can't make the deal with Iran deal, especially\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"germany is going through massive\"\n",
            "germany is going through massive attacks to its people by the U.S.! is he was a bad deal. but i'm smart results to those who\n",
            "with truecase:\n",
            "raw truecase: Germany is going through massive attacks to its people by the U. S.! is he was a bad deal. But I'm smart results to those who\n",
            "Germany is going through massive attacks to its people by the U. S.! is he was a bad deal. But I'm smart results to those who\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"germany is going through massive\"\n",
            "germany is going through massive attacks to its stupid to the loyal to millions of people who are sticking with me in las vegas yesterday\n",
            "with truecase:\n",
            "raw truecase: Germany is going through massive attacks to its stupid to the loyal to millions of people who are sticking with me in Las Vegas yesterday\n",
            "Germany is going through massive attacks to its stupid to the loyal to millions of people who are sticking with me in Las Vegas yesterday\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"germany is going through massive\"\n",
            "germany is going through massive attacks to the failing world has made. they play golf. joan is just a presidential because his failed was just\n",
            "with truecase:\n",
            "raw truecase: Germany is going through massive attacks to the failing world has made. They play golf. Joan is just a Presidential because his failed was just\n",
            "Germany is going through massive attacks to the failing world has made. They play golf. Joan is just a Presidential because his failed was just\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"reuters polling just thank you!\"\n",
            "reuters polling just thank you! #MakeAmericaGreatAgain #Trump2016 #IACaucus location at great. important to vote! #MakeAmericaGreatAgain #Trump2016 #MakeAmericaGreatAgain #TrumpTrain #IACaucus location to so important to vote!\n",
            "with truecase:\n",
            "raw truecase: Reuters polling just thank you! #Makeamericagreatagain #Trump2016 #Iacaucus location at great. important to vote! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trumptrain #Iacaucus location to so important to vote!\n",
            "Reuters polling just thank you! #Makeamericagreatagain #Trump2016 #Iacaucus location at great. important to vote! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trumptrain #Iacaucus location to so important to vote!\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"reuters polling just thank you!\"\n",
            "reuters polling just thank you! #MakeAmericaGreatAgain #Trump2016 #IACaucus location at great. important to vote! #MakeAmericaGreatAgain #Trump2016 #MakeAmericaGreatAgain #TrumpTrain #TrumpTrain #TrumpTrain to get out of the\n",
            "with truecase:\n",
            "raw truecase: Reuters polling just thank you! #Makeamericagreatagain #Trump2016 #Iacaucus location at great. important to vote! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trumptrain #Trumptrain #Trumptrain to get out of the\n",
            "Reuters polling just thank you! #Makeamericagreatagain #Trump2016 #Iacaucus location at great. important to vote! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trumptrain #Trumptrain #Trumptrain to get out of the\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"reuters polling just thank you!\"\n",
            "reuters polling just thank you! #MakeAmericaGreatAgain #Trump2016 #IACaucus location at great. somebody likes talking about the deal, and now it is too much to those\n",
            "with truecase:\n",
            "raw truecase: Reuters polling just thank you! #Makeamericagreatagain #Trump2016 #Iacaucus location at great. Somebody likes talking about the deal, and now it is too much to those\n",
            "Reuters polling just thank you! #Makeamericagreatagain #Trump2016 #Iacaucus location at great. Somebody likes talking about the deal, and now it is too much to those\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"reuters polling just thank you!\"\n",
            "reuters polling just thank you! #MakeAmericaGreatAgain #Trump2016 #IACaucus location at tomorrow. important to talk about! hell. -- he would sell fast without admitting her very\n",
            "with truecase:\n",
            "raw truecase: Reuters polling just thank you! #Makeamericagreatagain #Trump2016 #Iacaucus location at tomorrow. important to talk about! hell.-- he would sell fast without admitting her very\n",
            "Reuters polling just thank you! #Makeamericagreatagain #Trump2016 #Iacaucus location at tomorrow. important to talk about! hell.-- he would sell fast without admitting her very\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 89%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_eab8c186-0334-423f-b382-e5043f716641\", \"model.zip\", 38834140)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3321/3321 [==============================] - 352s 106ms/step - loss: 2.3496 - accuracy: 0.4763\n",
            "Epoch 7/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 1.9569 - accuracy: 0.5477\n",
            "----- Generating text after Epoch: 6\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"the record 13th season of\"\n",
            "the record 13th season of ‘All star’ @CelebApprentice. where they're coming from. #IACaucus location at so important to vote! #MakeAmericaGreatAgain #Trump2016 #MakeAmericaGreatAgain #Trump2016 #IACaucus #FITN\n",
            "with truecase:\n",
            "raw truecase: The record 13th season of ‘ all Star ’ @Celebapprentice. where they're coming from. #Iacaucus location at so important to vote! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trump2016 #Iacaucus #Fitn\n",
            "The record 13th season of ‘ all Star ’ @Celebapprentice. where they're coming from. #Iacaucus location at so important to vote! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trump2016 #Iacaucus #Fitn\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"the record 13th season of\"\n",
            "the record 13th season of ‘All star’ @CelebApprentice. where they're coming from. try to create a situation. -- sun tzu more than your business.” –\n",
            "with truecase:\n",
            "raw truecase: The record 13th season of ‘ all Star ’ @Celebapprentice. where they're coming from. try to create a situation.-- sun tzu more than your business. ” –\n",
            "The record 13th season of ‘ all Star ’ @Celebapprentice. where they're coming from. try to create a situation.-- sun tzu more than your business. ” –\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"the record 13th season of\"\n",
            "the record 13th season of ‘All star’ @CelebApprentice. where they're coming from. #IACaucus location at so important to vote! #MakeAmericaGreatAgain #Trump2016 #AmericaFirst #TrumpTrain I visit\n",
            "with truecase:\n",
            "raw truecase: The record 13th season of ‘ all Star ’ @Celebapprentice. where they're coming from. #Iacaucus location at so important to vote! #Makeamericagreatagain #Trump2016 #Americafirst #Trumptrain I visit\n",
            "The record 13th season of ‘ all Star ’ @Celebapprentice. where they're coming from. #Iacaucus location at so important to vote! #Makeamericagreatagain #Trump2016 #Americafirst #Trumptrain I visit\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"the record 13th season of\"\n",
            "the record 13th season of @CelebApprentice. where him question nicklaus increased over ryan telling me discussing my apprentice to tonight's #CelebrityApprentice cover went through a\n",
            "with truecase:\n",
            "raw truecase: The record 13th season of @Celebapprentice. where him question Nicklaus increased over Ryan telling me discussing my apprentice to tonight's #Celebrityapprentice cover went through a\n",
            "The record 13th season of @Celebapprentice. where him question Nicklaus increased over Ryan telling me discussing my apprentice to tonight's #Celebrityapprentice cover went through a\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"the reason that president obama\"\n",
            "the reason that president obama did NOTHING about it. they're spending country with members and can’t fire us! we can get it done. let’s make\n",
            "with truecase:\n",
            "raw truecase: The reason that President Obama did nothing about it. They're spending country with members and can ’ t fire us! we can get it done. Let ’ s make\n",
            "The reason that President Obama did NOTHING about it. They're spending country with members and can ’ t fire us! we can get it done. Let ’ s make\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"the reason that president obama\"\n",
            "the reason that president obama did NOTHING about it. they're coming from. try to create a situation. -- increased more future security by the war\n",
            "with truecase:\n",
            "raw truecase: The reason that President Obama did nothing about it. They're coming from. try to create a situation.-- increased more future security by the war\n",
            "The reason that President Obama did NOTHING about it. They're coming from. try to create a situation.-- increased more future security by the war\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"the reason that president obama\"\n",
            "the reason that president obama did NOTHING about it. radical islamic terror attack yesterday. get tough and crime, borders etc. will fail to reach deal\n",
            "with truecase:\n",
            "raw truecase: The reason that President Obama did nothing about it. radical Islamic terror attack yesterday. get tough and crime, borders etc. will fail to reach deal\n",
            "The reason that President Obama did NOTHING about it. radical Islamic terror attack yesterday. get tough and crime, borders etc. will fail to reach deal\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"the reason that president obama\"\n",
            "the reason that president obama is hagel as laughing and start some so-called right long when and many of other african american for your country\n",
            "with truecase:\n",
            "raw truecase: The reason that President Obama is Hagel as laughing and start some so-called right long when and many of other African American for your country\n",
            "The reason that President Obama is Hagel as laughing and start some so-called right long when and many of other African American for your country\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 89%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b3413e1c-ecb6-4fc3-b99a-f609b332ae01\", \"model.zip\", 38801161)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3321/3321 [==============================] - 360s 108ms/step - loss: 1.9569 - accuracy: 0.5477\n",
            "Epoch 8/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 1.6427 - accuracy: 0.6117\n",
            "----- Generating text after Epoch: 7\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"opportunities only present themselves if\"\n",
            "opportunities only present themselves if you are out there and never had a job, has had a tough time. that's politics! where we explain that\n",
            "with truecase:\n",
            "raw truecase: Opportunities only present themselves if you are out there and never had a job, has had a tough time. That's politics! where we explain that\n",
            "Opportunities only present themselves if you are out there and never had a job, has had a tough time. That's politics! where we explain that\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"opportunities only present themselves if\"\n",
            "opportunities only present themselves if you take advantage of yourself and NY times that is a senator like a dog. at he calls me I\n",
            "with truecase:\n",
            "raw truecase: Opportunities only present themselves if you take advantage of yourself and NY times that is a Senator like a dog. At he calls me I\n",
            "Opportunities only present themselves if you take advantage of yourself and NY times that is a Senator like a dog. At he calls me I\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"opportunities only present themselves if\"\n",
            "opportunities only present themselves if you are out there and never had a job, was hard at using the word laws now! is to see\n",
            "with truecase:\n",
            "raw truecase: Opportunities only present themselves if you are out there and never had a job, was hard at using the word laws now! is to see\n",
            "Opportunities only present themselves if you are out there and never had a job, was hard at using the word laws now! is to see\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"opportunities only present themselves if\"\n",
            "opportunities only present themselves if there off. there's nothing nobody like our is! also, thx back for nice your book sounds great! thank you service\n",
            "with truecase:\n",
            "raw truecase: Opportunities only present themselves if there off. There's nothing nobody like our is! also, Thx back for nice your book sounds great! thank you service\n",
            "Opportunities only present themselves if there off. There's nothing nobody like our is! also, Thx back for nice your book sounds great! thank you service\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"I will be meeting general\"\n",
            "I will be meeting general general and other swing states and #TimeToGetTough was out of control, expensive and that the biggest supporters will be back\n",
            "with truecase:\n",
            "raw truecase: I will be meeting general general and other swing States and #Timetogettough was out of control, expensive and that the biggest supporters will be back\n",
            "I will be meeting general general and other swing States and #Timetogettough was out of control, expensive and that the biggest supporters will be back\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"I will be meeting general\"\n",
            "I will be meeting general general and other swing states and #TimeToGetTough was out of control, expensive and that the biggest supporters will be back\n",
            "with truecase:\n",
            "raw truecase: I will be meeting general general and other swing States and #Timetogettough was out of control, expensive and that the biggest supporters will be back\n",
            "I will be meeting general general and other swing States and #Timetogettough was out of control, expensive and that the biggest supporters will be back\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"I will be meeting general\"\n",
            "I will be meeting general general and other swing states and #TimeToGetTough was every popular vote i'm representing me in business of the apprentice. I\n",
            "with truecase:\n",
            "raw truecase: I will be meeting general general and other swing States and #Timetogettough was every popular vote I'm representing me in business of the apprentice. I\n",
            "I will be meeting general general and other swing States and #Timetogettough was every popular vote I'm representing me in business of the apprentice. I\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"I will be meeting general\"\n",
            "I will be meeting general @Lawrence with all week. @Lawrence is (cont) (cont) (cont) is actually genius at tax it brings all flights from obama,\n",
            "with truecase:\n",
            "raw truecase: I will be meeting general @Lawrence with all week. @Lawrence is( CONT)( CONT)( CONT) is actually genius at tax it brings all flights from Obama,\n",
            "I will be meeting general @Lawrence with all week. @Lawrence is( CONT)( CONT)( CONT) is actually genius at tax it brings all flights from Obama,\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 89%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_198a2719-6640-4657-a0b3-0af5410144b5\", \"model.zip\", 38861441)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3321/3321 [==============================] - 380s 115ms/step - loss: 1.6427 - accuracy: 0.6117\n",
            "Epoch 9/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 1.3980 - accuracy: 0.6627\n",
            "----- Generating text after Epoch: 8\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"make it special! no better\"\n",
            "make it special! no better place to celebrate the eve than the most elite hotel in downtown @TrumpSoHo is a top destination located on the\n",
            "with truecase:\n",
            "raw truecase: Make it special! no better place to celebrate the eve than the most elite hotel in downtown @Trumpsoho is a top destination located on the\n",
            "Make it special! no better place to celebrate the eve than the most elite hotel in downtown @Trumpsoho is a top destination located on the\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"make it special! no better\"\n",
            "make it special! no better place to celebrate the eve than the most elite hotel in downtown toronto is the most elite in a winner\n",
            "with truecase:\n",
            "raw truecase: Make it special! no better place to celebrate the eve than the most elite hotel in downtown Toronto is the most elite in a winner\n",
            "Make it special! no better place to celebrate the eve than the most elite hotel in downtown Toronto is the most elite in a winner\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"make it special! no better\"\n",
            "make it special! no better place to celebrate the eve than the most elite elite hotel. hotel. @TrumpSoHo others. everyone. to daily. the rules of\n",
            "with truecase:\n",
            "raw truecase: Make it special! no better place to celebrate the eve than the most elite elite hotel. Hotel. @Trumpsoho others. everyone. to daily. The rules of\n",
            "Make it special! no better place to celebrate the eve than the most elite elite hotel. Hotel. @Trumpsoho others. everyone. to daily. The rules of\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"make it special! no better\"\n",
            "make it special! no better place a terrific or beat hillary just never had me to let for my watch! #MakeAmericaGreatAgain #Trump2016 #MakeAmericaGreatAgain #Trump2016 #AmericaFirst\n",
            "with truecase:\n",
            "raw truecase: Make it special! no better place a terrific or beat Hillary just never had me to let for my watch! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trump2016 #Americafirst\n",
            "Make it special! no better place a terrific or beat Hillary just never had me to let for my watch! #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Trump2016 #Americafirst\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"success is not final, failure\"\n",
            "success is not final, failure is not fatal: it is the courage to continue that counts. -- winston churchill -- churchill will be a lot\n",
            "with truecase:\n",
            "raw truecase: Success is not final, failure is not fatal: it is the courage to continue that counts.-- Winston Churchill-- Churchill will be a lot\n",
            "Success is not final, failure is not fatal: it is the courage to continue that counts.-- Winston Churchill-- Churchill will be a lot\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"success is not final, failure\"\n",
            "success is not final, failure is not fatal: it is the courage to continue that counts. -- winston churchill -- churchill will be a lot\n",
            "with truecase:\n",
            "raw truecase: Success is not final, failure is not fatal: it is the courage to continue that counts.-- Winston Churchill-- Churchill will be a lot\n",
            "Success is not final, failure is not fatal: it is the courage to continue that counts.-- Winston Churchill-- Churchill will be a lot\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"success is not final, failure\"\n",
            "success is not final, failure is not fatal: it is the courage to continue that counts. -- winston churchill -- churchill will be a lot\n",
            "with truecase:\n",
            "raw truecase: Success is not final, failure is not fatal: it is the courage to continue that counts.-- Winston Churchill-- Churchill will be a lot\n",
            "Success is not final, failure is not fatal: it is the courage to continue that counts.-- Winston Churchill-- Churchill will be a lot\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"success is not final, failure\"\n",
            "success is not final, failure is not fatal: it is the courage to continue that counts. -- winston churchill -- he should have been pulling\n",
            "with truecase:\n",
            "raw truecase: Success is not final, failure is not fatal: it is the courage to continue that counts.-- Winston Churchill-- he should have been pulling\n",
            "Success is not final, failure is not fatal: it is the courage to continue that counts.-- Winston Churchill-- he should have been pulling\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 89%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c292975d-18cc-4e72-90f8-cf980804e92c\", \"model.zip\", 38819559)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3321/3321 [==============================] - 371s 112ms/step - loss: 1.3980 - accuracy: 0.6627\n",
            "Epoch 10/10\n",
            "3321/3321 [==============================] - ETA: 0s - loss: 1.2062 - accuracy: 0.7045\n",
            "----- Generating text after Epoch: 9\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"I will be interviewed by\"\n",
            "I will be interviewed by @MariaBartiromo at 6:00 A.M. @FoxBusiness. enjoy! #Trump2016 #MakeAmericaGreatAgain #Trump2016 #MakeAmericaGreatAgain #FITN #FITN carolina. #MakeAmericaGreatAgain #Trump2016 #SuperTuesday #MakeAmericaGreatAgain #Trump2016 #IACaucus #FITN\n",
            "with truecase:\n",
            "raw truecase: I will be interviewed by @Mariabartiromo at 6:00 a. M. @Foxbusiness. enjoy! #Trump2016 #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Fitn #Fitn Carolina. #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Iacaucus #Fitn\n",
            "I will be interviewed by @Mariabartiromo at 6:00 a. M. @Foxbusiness. enjoy! #Trump2016 #Makeamericagreatagain #Trump2016 #Makeamericagreatagain #Fitn #Fitn Carolina. #Makeamericagreatagain #Trump2016 #Supertuesday #Makeamericagreatagain #Trump2016 #Iacaucus #Fitn\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"I will be interviewed by\"\n",
            "I will be interviewed by @MariaBartiromo at 6:00 A.M. @FoxBusiness. enjoy! you make a total disaster! 90 million will always &amp; my total name to\n",
            "with truecase:\n",
            "raw truecase: I will be interviewed by @Mariabartiromo at 6:00 a. M. @Foxbusiness. enjoy! you make a total disaster! 90 million will always& my total name to\n",
            "I will be interviewed by @Mariabartiromo at 6:00 a. M. @Foxbusiness. enjoy! you make a total disaster! 90 million will always& my total name to\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"I will be interviewed by\"\n",
            "I will be interviewed by @MariaBartiromo at 6:00 A.M. @FoxBusiness. enjoy! incredible a total winner tonight. I am proud of me and I still doesn't\n",
            "with truecase:\n",
            "raw truecase: I will be interviewed by @Mariabartiromo at 6:00 a. M. @Foxbusiness. enjoy! incredible a total winner tonight. I am proud of me and I still doesn't\n",
            "I will be interviewed by @Mariabartiromo at 6:00 a. M. @Foxbusiness. enjoy! incredible a total winner tonight. I am proud of me and I still doesn't\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"I will be interviewed by\"\n",
            "I will be interviewed by @MariaBartiromo at A.M. on @FoxNews at 8:00 P.M. enjoy! watch tonight at 8PM on @NBC. they're talking about. mexico fixed\n",
            "with truecase:\n",
            "raw truecase: I will be interviewed by @Mariabartiromo at a. M. On @Foxnews at 8: 00 P. M. enjoy! watch tonight at 8p M on @Nbc. They're talking about. Mexico fixed\n",
            "I will be interviewed by @Mariabartiromo at a. M. On @Foxnews at 8: 00 P. M. enjoy! watch tonight at 8p M on @Nbc. They're talking about. Mexico fixed\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"isn't it terrible that @megynkelly\"\n",
            "isn't it terrible that @megynkelly used for poll people. @Morning_Joe = best way to buy your own house and whose of contract for us today?\n",
            "with truecase:\n",
            "raw truecase: Isn'T it terrible that @Megynkelly used for poll people. @Morning_Joe= best way to buy your own house and whose of contract for us today?\n",
            "Isn'T it terrible that @Megynkelly used for poll people. @Morning_Joe= best way to buy your own house and whose of contract for us today?\n",
            "\n",
            "----- diversity: 0.4\n",
            "----- Generating with seed: \"isn't it terrible that @megynkelly\"\n",
            "isn't it terrible that @megynkelly used for ZERO people. #Trump2016 #MakeAmericaGreatAgain #ImWithYou Tickets: home to #Trump2016 #MakeAmericaGreatAgain #ImWithYou Tickets: Tickets: #FITN #Trump2016 #MakeAmericaGreatAgain #Trump2016 #SuperTuesday\n",
            "with truecase:\n",
            "raw truecase: Isn'T it terrible that @Megynkelly used for zero people. #Trump2016 #Makeamericagreatagain #Imwithyou tickets: home to #Trump2016 #Makeamericagreatagain #Imwithyou tickets: tickets: #Fitn #Trump2016 #Makeamericagreatagain #Trump2016 #Supertuesday\n",
            "Isn'T it terrible that @Megynkelly used for ZERO people. #Trump2016 #Makeamericagreatagain #Imwithyou tickets: home to #Trump2016 #Makeamericagreatagain #Imwithyou tickets: tickets: #Fitn #Trump2016 #Makeamericagreatagain #Trump2016 #Supertuesday\n",
            "\n",
            "----- diversity: 0.6\n",
            "----- Generating with seed: \"isn't it terrible that @megynkelly\"\n",
            "isn't it terrible that @megynkelly used by poll numbers for the double thank you, we will have everywhere. MAKE AMERICA GREAT AGAIN! TRUMP CRUZ 11\n",
            "with truecase:\n",
            "raw truecase: Isn'T it terrible that @Megynkelly used by poll numbers for the double thank you, we will have everywhere. make America great again! Trump Cruz 11\n",
            "Isn'T it terrible that @Megynkelly used by poll numbers for the double thank you, we will have everywhere. MAKE AMERICA GREAT AGAIN! TRUMP CRUZ 11\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"isn't it terrible that @megynkelly\"\n",
            "isn't it terrible that @megynkelly used their poll nice, off new thank you! #MakeAmericaGreatAgain #Trump2016 #WIPrimary #FITN #Trump2016 Tickets: at on the late show with\n",
            "with truecase:\n",
            "raw truecase: Isn'T it terrible that @Megynkelly used their poll nice, off new thank you! #Makeamericagreatagain #Trump2016 #Wiprimary #Fitn #Trump2016 tickets: at on the late show with\n",
            "Isn'T it terrible that @Megynkelly used their poll nice, off new thank you! #Makeamericagreatagain #Trump2016 #Wiprimary #Fitn #Trump2016 tickets: at on the late show with\n",
            "\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 89%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d56133e4-6f60-48e5-82d0-d70e7969b0ff\", \"model.zip\", 38871728)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3321/3321 [==============================] - 362s 109ms/step - loss: 1.2062 - accuracy: 0.7045\n",
            "INFO:tensorflow:Assets written to: /content/model/assets\n",
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 89%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.index (deflated 65%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: content/model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5fa03cc7-2663-490f-bf06-ecb66f22f656\", \"model.zip\", 38873516)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3rPB0gQwaI"
      },
      "source": [
        "Code to generate tweets after model is trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8gEh0iiQsgd",
        "outputId": "56837e81-4c8f-4a71-d501-f8c7d96f3667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "NUM_TWEETS_TO_GENERATE = 100\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "# --- LOAD THE MODEL --- #\n",
        "# !unzip /content/model.zip\n",
        "!unzip -o /content/model.zip\n",
        "model = keras.models.load_model('/content/content/model')\n",
        "\n",
        "GENERATED_TWEET_LENGTH = 30\n",
        "\n",
        "f = open('/content/model-output.txt', 'w')\n",
        "for i in range(NUM_TWEETS_TO_GENERATE):\n",
        "    tweet = np.random.choice(tweets) # select random tweet\n",
        "    start_index = 0\n",
        "    generated = ''\n",
        "    sentence = tweet.split(' ')[start_index: start_index + INPUT_LENGTH]\n",
        "    generated += ' '.join(sentence)\n",
        "    print('----- Generating with seed: \"' + ' '.join(sentence) + '\"')\n",
        "\n",
        "    for i in range(GENERATED_TWEET_LENGTH):\n",
        "        x_pred = np.zeros((1, INPUT_LENGTH, len(words_list)))\n",
        "        for t, word in enumerate(sentence):\n",
        "            x_pred[0, t, word_to_index[word]] = 1.\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, TEMPERATURE)\n",
        "        next_word = index_to_word[next_index]\n",
        "        generated += ' ' + next_word\n",
        "        sentence = sentence[1:] + [next_word]\n",
        "\n",
        "    print(generated)\n",
        "    f.write(generated + '\\n')\n",
        "    print()\n",
        "f.close()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/model.zip\n",
            "  inflating: content/model/saved_model.pb  \n",
            "  inflating: content/model/variables/variables.index  \n",
            "  inflating: content/model/variables/variables.data-00000-of-00001  \n",
            "----- Generating with seed: \"#Analysis: as canadian provinces line\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5567d40af7cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mx_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEMPERATURE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer sequential: expected shape=(None, None, 4832), found shape=[None, 5, 7806]\n"
          ]
        }
      ]
    }
  ]
}